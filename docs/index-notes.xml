<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>An Introduction to Statistical Learning</title>
<link>https://orenbochman.github.io/notes-islr/#category=notes</link>
<atom:link href="https://orenbochman.github.io/notes-islr/index-notes.xml" rel="self" type="application/rss+xml"/>
<description>Personal website, portfolio and blog</description>
<image>
<url>https://orenbochman.github.io/notes-islr/images/nlp-brain-wordcloud.jpg</url>
<title>An Introduction to Statistical Learning</title>
<link>https://orenbochman.github.io/notes-islr/#category=notes</link>
</image>
<generator>quarto-1.6.39</generator>
<lastBuildDate>Thu, 19 Sep 2024 21:00:00 GMT</lastBuildDate>
<item>
  <title>Chapter 13: Multiple Testing</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/notes-islr/posts/ch13-multiple-testing/</link>
  <description><![CDATA[ 






<div class="no-row-height column-margin column-container"><div id="fig-v1.1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v1.1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/LvySJGj-88U?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v1.1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Opening Remarks
</figcaption>
</figure>
</div><div id="fig-v1.2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v1.2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/B9s8rpdNxU0?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v1.2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Examples and Framework
</figcaption>
</figure>
</div></div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
TL;DR - Multiple Testing 🔬🔬🔬
</div>
</div>
<div class="callout-body-container callout-body">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="../../images/in_a_nutshell.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Multiple Testing in a nutshell"><img src="https://orenbochman.github.io/notes-islr/images/in_a_nutshell.jpg" class="img-fluid figure-img" alt="Multiple Testing in a nutshell"></a></p>
<figcaption>Multiple Testing in a nutshell</figcaption>
</figure>
</div>
<p>Multiple testing refers to the practice of conducting multiple hypothesis tests simultaneously, which can lead to an increased risk of making at least one Type I error. The Family-wise Error Rate (FWER) and False Discovery Rate (FDR) are two common error rates used to control for the risks of multiple testing. The Bonferroni correction, Holm’s method, and the Benjamini-Hochberg procedure are popular methods to adjust p-values and control for these error rates. Re-sampling methods like permutation testing can also be used to approximate the null distribution of the test statistic when theoretical distributions are unknown or assumptions about the data are difficult to justify.</p>
<audio controls="1">
<source src="podcast.mp3" data-external="1" type="audio/mpeg">

</audio>
</div>
</div>
<p>Glossary of Key Terms</p>
<dl>
<dt>Hypothesis Testing</dt>
<dd>
A statistical method used to assess the evidence provided by data against a specific null hypothesis in favor of an alternative hypothesis.
</dd>
<dt>Null Hypothesis (H0)</dt>
<dd>
The default statement of no effect or no difference that we aim to disprove using statistical evidence.
</dd>
<dt>Alternative Hypothesis (Ha)</dt>
<dd>
The statement that contradicts the null hypothesis and represents the claim we want to support if there is enough evidence.
</dd>
<dt>Test Statistic</dt>
<dd>
A numerical summary of the data that is used to assess the compatibility of the data with the null hypothesis.
</dd>
<dt>P-value</dt>
<dd>
The probability of observing a test statistic as extreme as or more extreme than the one calculated from the data, assuming the null hypothesis is true.
</dd>
<dt>Type I Error</dt>
<dd>
Rejecting a true null hypothesis (false positive).
</dd>
<dt>Type II Error</dt>
<dd>
Failing to reject a false null hypothesis (false negative).
</dd>
<dt>Multiple Hypothesis Testing</dt>
<dd>
Performing multiple hypothesis tests simultaneously, which increases the probability of making at least one Type I error.
</dd>
<dt>Family-wise Error Rate (FWER)</dt>
<dd>
The probability of making at least one Type I error among all hypotheses tested.
</dd>
<dt>False Discovery Rate (FDR)</dt>
<dd>
The expected proportion of falsely rejected null hypotheses among all rejected null hypotheses.
</dd>
<dt>Bonferroni Correction</dt>
<dd>
A method to control the FWER by dividing the desired overall significance level by the number of tests.
</dd>
<dt>Holm’s Method</dt>
<dd>
A step-down method to control the FWER that adjusts p-value thresholds sequentially, potentially leading to more rejections than the Bonferroni correction.
</dd>
<dt>Benjamini-Hochberg Procedure</dt>
<dd>
A method to control the FDR by identifying the largest p-value that satisfies a specific criterion and rejecting all null hypotheses with p-values less than or equal to this identified p-value.
</dd>
<dt>Re-sampling Methods</dt>
<dd>
Techniques like permutation testing that use random sampling with replacement from the observed data to approximate the null distribution of the test statistic, especially helpful when theoretical null distributions are unknown or assumptions about the data are difficult to justify.
</dd>
<dt>Permutation Testing</dt>
<dd>
A re-sampling method where data points are randomly reassigned to different groups to create new datasets under the assumption of the null hypothesis. This allows for the estimation of the null distribution of the test statistic without relying on specific distributional assumptions.
</dd>
</dl>
<section id="chapter-outline" class="level2">
<h2 class="anchored" data-anchor-id="chapter-outline">Chapter Outline</h2>
<p><strong>Central Problem</strong>: When testing multiple hypotheses simultaneously, the probability of making at least one Type I error (false positive) increases dramatically. This necessitates the use of specific methods to control this error rate.</p>
<ol type="1">
<li>Key Concepts:</li>
</ol>
<p>Type I Error: Rejecting the null hypothesis when it is actually true (false positive). Type II Error: Failing to reject the null hypothesis when it is actually false (false negative). Family-Wise Error Rate (FWER): The probability of making at least one Type I error across all tested hypotheses. False Discovery Rate (FDR): The expected proportion of rejected null hypotheses that are actually false positives. Multiple Testing Correction: Adjusting p-values or rejection thresholds to account for the increased risk of Type I errors when testing multiple hypotheses.</p>
<ol start="2" type="1">
<li>Methods for Controlling FWER:</li>
</ol>
<p>Bonferroni Correction: The simplest and most conservative method. It divides the desired alpha level (the probability of making a Type I error) by the number of hypotheses being tested (m). This new, stricter alpha level is then used as the threshold for rejecting each individual hypothesis. Formula: Reject H0j if p-value &lt; α/m Advantages: Easy to implement. Disadvantages: Can be overly conservative, leading to higher Type II error rates, especially with a large number of hypotheses. Holm’s Method: A step-down procedure that offers more power than Bonferroni while still controlling the FWER. It orders the p-values from smallest to largest and compares each p-value to a sequentially adjusted alpha level. Formula: Reject H0j if p(j) &lt; α/(m + 1 - j), where p(j) is the jth smallest p-value. Advantages: More powerful than Bonferroni. Disadvantages: Still relatively conservative. Tukey’s and Scheffé’s Methods: Specialized methods tailored for specific types of multiple comparisons. Tukey’s method is designed for all pairwise comparisons of means, while Scheffé’s method is more general and allows for any linear combination of means to be tested.</p>
<ol start="3" type="1">
<li>Methods for Controlling FDR:</li>
</ol>
<p>Benjamini-Hochberg Procedure: A step-up procedure that controls the FDR at a desired level (q). It orders the p-values from smallest to largest and compares each p-value to a sequentially adjusted q-value threshold. Formula: Reject H0j if p(j) &lt; qj/m Advantages: Less conservative than FWER control methods, leading to higher power. Disadvantages: May lead to a higher proportion of false positives compared to FWER control methods. 4. Re-Sampling Approaches:</p>
<p>When the theoretical null distribution of a test statistic is unknown, re-sampling methods (e.g., permutation tests) can be used to approximate the null distribution and calculate p-values. This is particularly useful for small sample sizes or complex test statistics.</p>
<ol start="5" type="1">
<li>Illustrations: There are many examples using simulated data and real datasets (Fund dataset, Khan dataset) to demonstrate the impact of multiple testing on error rates and the effectiveness of different correction methods.</li>
</ol>
</section>
<section id="key-quotes" class="level2">
<h2 class="anchored" data-anchor-id="key-quotes">Key Quotes:</h2>
<blockquote class="blockquote">
<p>“The Bonferroni correction gives us peace of mind that we have not falsely rejected too many null hypotheses, but for a price: we reject few null hypotheses, and thus will typically make quite a few Type II errors.”</p>
</blockquote>
<blockquote class="blockquote">
<p>“If m = 10,000, then we expect to falsely reject 100 null hypotheses by chance! That’s a lot of Type I errors, i.e., false positives!”</p>
</blockquote>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion:</h2>
<p>Multiple hypothesis testing is a common challenge in data analysis, requiring careful consideration of error control methods. Choosing the appropriate method depends on the specific research question, desired level of error control, and available resources. Re-sampling approaches offer a flexible alternative when theoretical null distributions are unavailable.</p>
</section>
<section id="multiple-hypothesis-testing-study-guide" class="level2">
<h2 class="anchored" data-anchor-id="multiple-hypothesis-testing-study-guide">Multiple Hypothesis Testing Study Guide</h2>
<p>Short Answer Questions Instructions: Answer the following questions in 2-3 sentences each.</p>
<ol type="1">
<li>What is the purpose of a test statistic in hypothesis testing?</li>
<li>Explain the concept of a p-value and its role in hypothesis testing.</li>
<li>What is the difference between a Type I error and a Type II error?</li>
<li>Why is multiple hypothesis testing problematic, even if we control the Type I error rate for each individual test?</li>
<li>What is the family-wise error rate (FWER), and how does it differ from the Type I error rate?</li>
<li>Explain how the Bonferroni correction controls the FWER.</li>
<li>What is the advantage of Holm’s method over the Bonferroni correction for controlling the FWER?</li>
<li>Define the false discovery rate (FDR). How does it differ from the FWER?</li>
<li>Describe the Benjamini-Hochberg procedure for controlling the FDR.</li>
<li>When might a re-sampling approach be useful for multiple hypothesis testing? Provide an example.</li>
</ol>
</section>
<section id="short-answer-key" class="level2">
<h2 class="anchored" data-anchor-id="short-answer-key">Short Answer Key</h2>
<ol type="1">
<li>A test statistic summarizes the data’s compatibility with the null hypothesis. Its value helps determine the strength of evidence against the null hypothesis.</li>
<li>The p-value is the probability of observing a test statistic as extreme as, or more extreme than, the one calculated from the data, assuming the null hypothesis is true. A smaller p-value indicates stronger evidence against the null hypothesis.</li>
<li>A Type I error occurs when we reject a true null hypothesis, while a Type II error occurs when we fail to reject a false null hypothesis.</li>
<li>When performing multiple hypothesis tests, the probability of making at least one Type I error increases, even if the individual Type I error rate for each test is controlled. This leads to an inflated overall false positive rate.</li>
<li>The family-wise error rate (FWER) is the probability of making at least one Type I error among all hypotheses tested. Unlike the Type I error rate which focuses on a single test, the FWER considers the probability of making any false rejections across multiple tests.</li>
<li>The Bonferroni correction controls the FWER by dividing the desired overall significance level (alpha) by the number of tests (m). This more stringent significance level for each individual test ensures that the FWER is maintained at or below alpha.</li>
<li>Holm’s method is a step-down procedure that adjusts the p-value thresholds for each hypothesis sequentially, starting with the smallest p-value. This allows for potentially more rejections compared to the Bonferroni correction, which uses a fixed threshold for all tests, while still controlling the FWER.</li>
<li>The false discovery rate (FDR) is the expected proportion of false rejections (Type I errors) among all rejected hypotheses. It focuses on controlling the rate of false positives among the discoveries made, rather than controlling the probability of making any Type I error like the FWER.</li>
<li>The Benjamini-Hochberg procedure controls the FDR by ranking p-values and finding the largest p-value that satisfies a specific criterion. It then rejects all null hypotheses with p-values less than or equal to this identified p-value.</li>
<li>Re-sampling approaches are useful when the theoretical null distribution of the test statistic is unknown, or when we want to avoid making strong assumptions about the data. For instance, in a two-sample t-test with small sample sizes, where the normality assumption might not hold, we can use permutation testing to approximate the null distribution and calculate p-values.</li>
</ol>
</section>
<section id="essay-questions" class="level2">
<h2 class="anchored" data-anchor-id="essay-questions">Essay Questions</h2>
<ol type="1">
<li>Discuss the trade-off between controlling the FWER and the power of multiple hypothesis tests. How do different correction methods impact this trade-off?</li>
<li>In what situations might controlling the FDR be more appropriate than controlling the FWER? Explain your reasoning with examples.</li>
<li>Compare and contrast the Bonferroni correction and Holm’s method for controlling the FWER. Discuss their strengths and weaknesses, and provide scenarios where one might be preferred over the other.</li>
<li>Explain the concept of permutation testing and its use in multiple hypothesis testing when theoretical null distributions are unavailable. How does it help in estimating p-values?</li>
<li>Describe a real-world example of multiple hypothesis testing and discuss the implications of choosing different error control methods (FWER, FDR) for the specific problem.</li>
</ol>
</section>
<section id="slides-and-chapter" class="level2">
<h2 class="anchored" data-anchor-id="slides-and-chapter">Slides and Chapter</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slides.pdf" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Chapter Slides"><embed src="slides.pdf" class="col-page" style="width:5in;height:3.8in"></a></p>
<figcaption>Chapter Slides</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="ch13.pdf" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Chapter"><embed src="ch13.pdf" class="col-page" width="800" height="1000"></a></p>
<figcaption>Chapter</figcaption>
</figure>
</div>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div>CC SA BY-NC-ND</div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2024,
  author = {Bochman, Oren},
  title = {Chapter 13: {Multiple} {Testing}},
  date = {2024-09-20},
  url = {https://orenbochman.github.io/notes-islr/posts/ch13-multiple-testing/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2024" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2024. <span>“Chapter 13: Multiple Testing.”</span>
September 20, 2024. <a href="https://orenbochman.github.io/notes-islr/posts/ch13-multiple-testing/">https://orenbochman.github.io/notes-islr/posts/ch13-multiple-testing/</a>.
</div></div></section></div> ]]></description>
  <category>notes</category>
  <category>edx</category>
  <category>podcast</category>
  <guid>https://orenbochman.github.io/notes-islr/posts/ch13-multiple-testing/</guid>
  <pubDate>Thu, 19 Sep 2024 21:00:00 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/notes-islr/images/nlp-brain-wordcloud.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Chapter 12: Unsupervised Learning</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/notes-islr/posts/ch12-unsupervised-learning/</link>
  <description><![CDATA[ 






<div class="no-row-height column-margin column-container"><div id="fig-v1.1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v1.1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/LvySJGj-88U?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v1.1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Opening Remarks
</figcaption>
</figure>
</div><div id="fig-v1.2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v1.2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/B9s8rpdNxU0?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v1.2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Examples and Framework
</figcaption>
</figure>
</div></div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
TL;DR - Statistical Learning in a Nutshell
</div>
</div>
<div class="callout-body-container callout-body">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="../../images/in_a_nutshell.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Statistical Learning in a nutshell"><img src="https://orenbochman.github.io/notes-islr/images/in_a_nutshell.jpg" class="img-fluid figure-img" alt="Statistical Learning in a nutshell"></a></p>
<figcaption>Statistical Learning in a nutshell</figcaption>
</figure>
</div>
<p>Statistical learning is a set of tools for understanding data and building models that can be used for prediction or inference. The fundamental goal is to learn a function <img src="https://latex.codecogs.com/png.latex?(f)"> that captures the relationship between input variables (predictors) and an output variable (response). This learned function can then be used to make predictions for new observations or for inference i.e.&nbsp;to understand the underlying relationship between the variables.</p>
<audio controls="1">
<source src="podcast.mp3" data-external="1" type="audio/mpeg">

</audio>
</div>
</div>
<section id="slides-and-chapter" class="level2">
<h2 class="anchored" data-anchor-id="slides-and-chapter">Slides and Chapter</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slides.pdf" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Chapter Slides"><embed src="slides.pdf" class="col-page" style="width:5in;height:3.8in"></a></p>
<figcaption>Chapter Slides</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="ch02.pdf" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Chapter"><embed src="ch02.pdf" class="col-page" width="800" height="1000"></a></p>
<figcaption>Chapter</figcaption>
</figure>
</div>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div>CC SA BY-NC-ND</div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2024,
  author = {Bochman, Oren},
  title = {Chapter 12: {Unsupervised} {Learning}},
  date = {2024-09-10},
  url = {https://orenbochman.github.io/notes-islr/posts/ch12-unsupervised-learning/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2024" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2024. <span>“Chapter 12: Unsupervised Learning.”</span>
September 10, 2024. <a href="https://orenbochman.github.io/notes-islr/posts/ch12-unsupervised-learning/">https://orenbochman.github.io/notes-islr/posts/ch12-unsupervised-learning/</a>.
</div></div></section></div> ]]></description>
  <category>notes</category>
  <category>edx</category>
  <category>podcast</category>
  <guid>https://orenbochman.github.io/notes-islr/posts/ch12-unsupervised-learning/</guid>
  <pubDate>Mon, 09 Sep 2024 21:00:00 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/notes-islr/images/nlp-brain-wordcloud.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Chapter 11: Survival Analysis</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/notes-islr/posts/ch11-survival-analysis-and-censored-data/</link>
  <description><![CDATA[ 






<div class="no-row-height column-margin column-container"><div id="fig-v1.1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v1.1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/LvySJGj-88U?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v1.1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Opening Remarks
</figcaption>
</figure>
</div><div id="fig-v1.2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v1.2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/B9s8rpdNxU0?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v1.2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Examples and Framework
</figcaption>
</figure>
</div></div>
<ol type="1">
<li><p>This chapter doen’t have a lab and is a bit dull.</p></li>
<li><p>The authors make significant effort to breathe life into it in the talks. But humor and jokes aside. Most of the examples and datasets from the book and make them sound mildly interesting, but my impression of the advertising data and a few others is that this is just data and that they never worked for an advertising company where most of the queations raised are quite diavervegent to the ones considered in the book.</p></li>
<li><p>IBM’s Watson beating the Jeopardy champions was exciting before the advent of LLMs. In reality IBM poured lots of resources into this demonstration of being able to beat some poor humans with a massive database of trivia. Later IBM had a very big headache trying to sell Watson to companies. IT took 10 years for LLM assistant to become both useful and in scale. If we consider the slide from the video we would notice that the project is realy using reinfocement learnin and not statistical learning or machine learning methods that are covered in the book.</p></li>
<li><p>A second story they mention is <strong>Nate Silver</strong>’s Five Thirty Eight site for prediction of the presidential and other elections. I find it amusing they mention this as Nate Silver is not a statistician. In reality most people use statistics as a tool to get their job done and are not full time statisticans. Nate Silver is a “rock star”. It’s worth mentioning though that predicing elections is isn’t hard mathematically - the challange is getting the details right and Nate Silver is good at that and thus deserves a lot of respect. There is very intersting work by Gelman and Tukey before on this topic. In fact John Tukey like Silver gained a lot of recognition, not from his amazing work on EDA, including the boxplot, the JAckknife the Fast Fourier Transform, designing spy plaens, naming the bit and software but for running election polls on NBC from 1960 to 1980. And a final point is that the best models as far as I know are using Bayesian methods which are not covered in this book to any great detail.</p></li>
<li><p><strong>Spam Detection</strong> - is a good example of Statistical Learning. Building a binary classifier using logistic regression is faitly easy to do and the maths is quite straight forward. The devil here is in the details. And spam is a moving target as spammers keep improving. It seems though that the real solution isn’t somuch a good filter but to make spamming unprofitable by making it easy to fine/sue spammers.</p></li>
<li><p>It covers the three of the datasets used in the book.</p>
<ol type="1">
<li>Wage data</li>
<li>Stock market data</li>
<li>Gene Expression Data</li>
</ol></li>
<li><p>ISL <span class="citation" data-cites="ISL">(James et al. 2013)</span> is an introduction text. <span class="citation" data-cites="ESL">(Hastie, Tibshirani, and Friedman 2009)</span> is the more comprehensive text.</p></li>
<li><p>Statistical learning is the author’s preferred term for machine learning and it is a bit different in that it considers the data orriginating from a data generating process (DGP) and the main goal is to uncover this process. In traditional ML the focus is on prediction.</p></li>
</ol>
<section id="premises" class="level2">
<h2 class="anchored" data-anchor-id="premises">Premises:</h2>
<ul>
<li>Statistical learning is not a series of black boxes - we need to understand the way the cogs of models come together.</li>
<li>While it is important to know what job is performed by each cog, it is not necessary to have the skills to construct the machine inside the box!</li>
<li>The readers are interested in applying the methods to real-world problems.</li>
</ul>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0">
<div id="ref-ESL" class="csl-entry">
Hastie, T., R. Tibshirani, and J. H. Friedman. 2009. <em>The Elements of Statistical Learning: Data Mining, Inference, and Prediction</em>. Springer Series in Statistics. Springer. <a href="https://books.google.co.il/books?id=eBSgoAEACAAJ">https://books.google.co.il/books?id=eBSgoAEACAAJ</a>.
</div>
<div id="ref-ISL" class="csl-entry">
James, G., D. Witten, T. Hastie, and R. Tibshirani. 2013. <em>An Introduction to Statistical Learning: With Applications in r</em>. Springer Texts in Statistics. Springer New York. <a href="https://books.google.co.il/books?id=qcI_AAAAQBAJ">https://books.google.co.il/books?id=qcI_AAAAQBAJ</a>.
</div>
</div></section><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div>CC SA BY-NC-ND</div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2024,
  author = {Bochman, Oren},
  title = {Chapter 11: {Survival} {Analysis}},
  date = {2024-09-01},
  url = {https://orenbochman.github.io/notes-islr/posts/ch11-survival-analysis-and-censored-data/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2024" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2024. <span>“Chapter 11: Survival Analysis.”</span>
September 1, 2024. <a href="https://orenbochman.github.io/notes-islr/posts/ch11-survival-analysis-and-censored-data/">https://orenbochman.github.io/notes-islr/posts/ch11-survival-analysis-and-censored-data/</a>.
</div></div></section></div> ]]></description>
  <category>notes</category>
  <category>edx</category>
  <guid>https://orenbochman.github.io/notes-islr/posts/ch11-survival-analysis-and-censored-data/</guid>
  <pubDate>Sat, 31 Aug 2024 21:00:00 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/notes-islr/images/nlp-brain-wordcloud.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Chapter 10: Deep Learning</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/notes-islr/posts/ch10-deep-learning/</link>
  <description><![CDATA[ 






<div class="no-row-height column-margin column-container"><div id="fig-v1.1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v1.1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/LvySJGj-88U?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v1.1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Opening Remarks
</figcaption>
</figure>
</div><div id="fig-v1.2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v1.2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/B9s8rpdNxU0?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v1.2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Examples and Framework
</figcaption>
</figure>
</div></div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
TL;DR - Deep Learning
</div>
</div>
<div class="callout-body-container callout-body">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="../../images/in_a_nutshell.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Deep Learning in a nutshell"><img src="https://orenbochman.github.io/notes-islr/images/in_a_nutshell.jpg" class="img-fluid figure-img" alt="Deep Learning in a nutshell"></a></p>
<figcaption>Deep Learning in a nutshell</figcaption>
</figure>
</div>
<p>Deep learning is a subfield of machine learning that is concerned with algorithms inspired by the structure and function of the brain called artificial neural networks. It has been applied to a wide range of applications, including computer vision, speech recognition, natural language processing, and more. Deep learning models are typically trained on large datasets using a technique called backpropagation, which adjusts the model’s weights to minimize the error between the predicted output and the true output. Popular deep learning frameworks include TensorFlow, Keras, and PyTorch.</p>
<audio controls="1">
<source src="podcast.mp3" data-external="1" type="audio/mpeg">

</audio>
</div>
</div>
<section id="slides-and-chapter" class="level2">
<h2 class="anchored" data-anchor-id="slides-and-chapter">Slides and Chapter</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slides.pdf" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Chapter Slides"><embed src="slides.pdf" class="col-page" style="width:5in;height:3.8in"></a></p>
<figcaption>Chapter Slides</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="ch10.pdf" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Chapter"><embed src="ch10.pdf" class="col-page" width="800" height="1000"></a></p>
<figcaption>Chapter</figcaption>
</figure>
</div>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div>CC SA BY-NC-ND</div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2024,
  author = {Bochman, Oren},
  title = {Chapter 10: {Deep} {Learning}},
  date = {2024-08-20},
  url = {https://orenbochman.github.io/notes-islr/posts/ch10-deep-learning/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2024" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2024. <span>“Chapter 10: Deep Learning.”</span> August
20, 2024. <a href="https://orenbochman.github.io/notes-islr/posts/ch10-deep-learning/">https://orenbochman.github.io/notes-islr/posts/ch10-deep-learning/</a>.
</div></div></section></div> ]]></description>
  <category>notes</category>
  <category>edx</category>
  <guid>https://orenbochman.github.io/notes-islr/posts/ch10-deep-learning/</guid>
  <pubDate>Mon, 19 Aug 2024 21:00:00 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/notes-islr/images/nlp-brain-wordcloud.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Chapter 9: Support Vector Machines</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/notes-islr/posts/ch09-svm/</link>
  <description><![CDATA[ 






<div class="no-row-height column-margin column-container"><div id="fig-v1.1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v1.1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/LvySJGj-88U?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v1.1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Opening Remarks
</figcaption>
</figure>
</div><div id="fig-v1.2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v1.2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/B9s8rpdNxU0?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v1.2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Examples and Framework
</figcaption>
</figure>
</div></div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
TL;DR - Support Vector Machines
</div>
</div>
<div class="callout-body-container callout-body">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="../../images/in_a_nutshell.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Support Vector Machines in a nutshell"><img src="https://orenbochman.github.io/notes-islr/images/in_a_nutshell.jpg" class="img-fluid figure-img" alt="Support Vector Machines in a nutshell"></a></p>
<figcaption>Support Vector Machines in a nutshell</figcaption>
</figure>
</div>
<ul>
<li><strong>Maximal Margin Classifier</strong>: The SVM finds the hyperplane that maximizes the margin between classes.</li>
<li><strong>Support Vector Classifier</strong>: The SVM allows for misclassification by introducing slack variables.</li>
<li><strong>Support Vector Machine</strong>: The SVM extends to nonlinear decision boundaries using kernels.</li>
<li><strong>KKT Conditions</strong>: The Karush-Kuhn-Tucker conditions are necessary for the SVM solution.</li>
<li><strong>Soft Margin</strong>: The SVM can handle noisy data by allowing for misclassification.</li>
<li><strong>Multi-Class SVM</strong>: The SVM can be extended to more than two classes.</li>
</ul>
<audio controls="1">
<source src="podcast.mp3" data-external="1" type="audio/mpeg">

</audio>
</div>
</div>
<section id="slides-and-chapter" class="level2">
<h2 class="anchored" data-anchor-id="slides-and-chapter">Slides and Chapter</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slides.pdf" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Chapter Slides"><embed src="slides.pdf" class="col-page" style="width:5in;height:3.8in"></a></p>
<figcaption>Chapter Slides</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="ch09.pdf" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Chapter"><embed src="ch09.pdf" class="col-page" width="800" height="1000"></a></p>
<figcaption>Chapter</figcaption>
</figure>
</div>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div>CC SA BY-NC-ND</div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2024,
  author = {Bochman, Oren},
  title = {Chapter 9: {Support} {Vector} {Machines}},
  date = {2024-08-10},
  url = {https://orenbochman.github.io/notes-islr/posts/ch09-svm/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2024" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2024. <span>“Chapter 9: Support Vector Machines.”</span>
August 10, 2024. <a href="https://orenbochman.github.io/notes-islr/posts/ch09-svm/">https://orenbochman.github.io/notes-islr/posts/ch09-svm/</a>.
</div></div></section></div> ]]></description>
  <category>notes</category>
  <category>edx</category>
  <category>podcast</category>
  <guid>https://orenbochman.github.io/notes-islr/posts/ch09-svm/</guid>
  <pubDate>Fri, 09 Aug 2024 21:00:00 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/notes-islr/images/nlp-brain-wordcloud.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Chapter 8: Trees</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/notes-islr/posts/ch08-tree-based-methods/</link>
  <description><![CDATA[ 





<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
TL;DR - Trees
</div>
</div>
<div class="callout-body-container callout-body">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="../../images/in_a_nutshell.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Trees in a nutshell"><img src="https://orenbochman.github.io/notes-islr/images/in_a_nutshell.jpg" class="img-fluid figure-img" alt="Trees in a nutshell"></a></p>
<figcaption>Trees in a nutshell</figcaption>
</figure>
</div>
<ul>
<li><strong>Tree-based methods</strong> are supervised learning algorithms that stratify the predictor space to make predictions.</li>
<li><strong>Decision trees</strong> are simple to interpret but may not be as competitive as other methods in terms of prediction accuracy.</li>
<li><strong>Ensembles of trees</strong>, such as bagging, boosting, and random forests, can improve prediction performance.</li>
<li><strong>Classification trees</strong> are used when the response is a categorical variable.</li>
</ul>
<audio controls="1">
<source src="podcast.mp3" data-external="1" type="audio/mpeg">

</audio>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tree based methods Video
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">

<p>Outline of first video</p>
<ol type="1">
<li>Introduction
<ul>
<li>Tree-based methods are supervised learning algorithms that stratify the predictor space to make predictions.</li>
<li>They are called decision trees because of their branching structure.</li>
<li>The CART (Classification and Regression Trees) algorithm is a popular example of a tree-based method.</li>
<li>Trees are simple to interpret but may not be as competitive as other methods in terms of prediction accuracy.</li>
<li>Ensembles of trees, such as bagging, boosting, and random forests, can improve prediction performance.</li>
</ul></li>
<li>Decision Trees
<ul>
<li>Example: Predicting baseball player salary based on years in the league and hits per season.</li>
<li>Process:</li>
<li>The data is split into regions based on predictor values.</li>
<li>Each region is assigned a prediction, typically the average response value for observations in that region.</li>
<li>Splits are chosen to minimize the variation of observations within each region.</li>
<li>Terminology:</li>
<li>Internal nodes: Nodes that are further split.</li>
<li>Terminal nodes (leaves): Nodes that are not further split.</li>
<li>Interpretation: The tree structure itself represents the model.</li>
</ul></li>
<li>Tree Growing Algorithm
<ul>
<li>Greedy approach:
<ul>
<li>Starts with the full dataset.</li>
<li>Finds the best split (predictor and split point) to minimize the variation within each resulting region.</li>
<li>Repeats the process for each resulting region until a stopping criterion is met.</li>
</ul></li>
<li>Stopping criteria:
<ul>
<li>Predefined number of nodes.</li>
<li>Minimum number of observations in a node.</li>
<li>Other criteria based on model complexity or performance.</li>
</ul></li>
</ul></li>
<li>Challenges and Limitations
<ul>
<li>Overfitting: Trees can be prone to overfitting the training data, leading to poor generalization performance.</li>
<li>Instability: Small changes in the training data can lead to large changes in the tree structure.</li>
<li>Limited flexibility: Trees can struggle to capture complex relationships between predictors and the response.</li>
</ul></li>
<li>Ensembles of Trees
<ul>
<li>Bagging: Creates multiple trees using bootstrap samples of the training data and averages their predictions.</li>
<li>Boosting: Creates a sequence of trees, where each tree focuses on correcting the errors of the previous trees.</li>
<li>Random forests: Creates multiple trees using random subsets of predictors at each split.</li>
</ul></li>
<li>Conclusion
<ul>
<li>Tree-based methods are versatile and interpretable tools for supervised learning.</li>
<li>Ensembles of trees can significantly improve prediction accuracy.</li>
<li>Further research is ongoing to develop more robust and efficient tree-based methods.</li>
</ul></li>
</ol>
</div>
</div>
</div>
<div class="no-row-height column-margin column-container"><div id="fig-8.1" class="quarto-float quarto-figure quarto-figure-center anchored callout-2-contents callout-collapse collapse show callout-margin-content">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-8.1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/QNnayf--_yk?list=PLoROMvodv4rPP6braWoRt5UCXYZ71GZIQ" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-8.1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Tree based methods
</figcaption>
</figure>
</div></div><div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
More details on Trees
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">

<p>Outline of second video</p>
<ul>
<li>The process of building a tree and making predictions</li>
<li>The question of how large should the tree be</li>
<li>The cost complexity pruning</li>
<li>The summary of the tree growing algorithm</li>
<li>The result of cross validation</li>
</ul>
</div>
</div>
</div>
<div class="no-row-height column-margin column-container"><div id="fig-8.2" class="quarto-float quarto-figure quarto-figure-center anchored callout-3-contents callout-collapse collapse show callout-margin-content">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-8.2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/JaoTOfTNOVk?list=PLoROMvodv4rPP6braWoRt5UCXYZ71GZIQ" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-8.2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: More details on Trees
</figcaption>
</figure>
</div></div><div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Classification Trees
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">

<p>Outline of third video</p>
<ul>
<li>Introduction
<ul>
<li>Regression trees are used when the response is quantitative.</li>
<li>Classification trees are used when the response is a categorical variable.</li>
<li>The technology is very similar, but the loss function and how to measure good performance are different.</li>
</ul></li>
<li>Classification Trees
<ul>
<li>Each observation is classified to the most commonly occurring class in the terminal node.</li>
<li>The tree is grown in the same way as for regression trees.</li>
<li>The criterion for making the splits is different.</li>
<li>One criterion is the classification error rate.</li>
<li>Another criterion is the Gini index, which is a measure of variability across the classes.</li>
<li>The deviance or cross-entropy is another criterion that is similar to the Gini index.</li>
</ul></li>
<li>Example: Heart Data
<ul>
<li>The heart data has a binary response called HD.</li>
<li>There are 303 patients.</li>
<li>There are 13 predictors.</li>
<li>A tree was grown using cross-validation.</li>
<li>The full tree is quite bushy.</li>
<li>The pruned tree has a size of 6.</li>
<li>The classification performance of the pruned tree is 25%.</li>
</ul></li>
<li>Comparison of Trees and Linear Models
<ul>
<li>Trees are not always the best method.</li>
<li>Linear models are better for some problems.</li>
<li>Trees are better for other problems.</li>
<li>Advantages and Disadvantages of Trees</li>
</ul></li>
<li>Advantages:
<ul>
<li>Simple to understand.</li>
<li>Can handle qualitative predictors.</li>
</ul></li>
<li>Disadvantages:
<ul>
<li>Do not predict as well as more state-of-the-art methods.</li>
</ul></li>
<li>Ensemble Methods
<ul>
<li>Ensemble methods combine trees to improve prediction accuracy.</li>
<li>One example of an ensemble method is random forests.</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div class="no-row-height column-margin column-container"><div id="fig-8.3" class="quarto-float quarto-figure quarto-figure-center anchored callout-4-contents callout-collapse collapse show callout-margin-content">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-8.3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/gLcfKSMKOb0?list=PLoROMvodv4rPP6braWoRt5UCXYZ71GZIQ" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-8.3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Classification Trees
</figcaption>
</figure>
</div></div><div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Bagging
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">

<p>Outline of fourth video</p>
<ul>
<li>Introduction
<ul>
<li>Bagging is a method of using trees to improve their prediction error.</li>
<li>It involves creating multiple trees and averaging their predictions.</li>
<li>The idea was proposed by Leo Breiman.</li>
</ul></li>
<li>Bagging Process
<ul>
<li>Bootstrap samples are drawn from the training set with replacement.</li>
<li>A tree is grown on each bootstrap sample.</li>
<li>The predictions of all trees are averaged to obtain the final prediction.</li>
</ul></li>
<li>Advantages of Bagging
<ul>
<li>Reduces variance by averaging multiple trees.</li>
<li>Can be applied to both regression and classification problems.</li>
<li>No need to prune trees.</li>
</ul></li>
<li>Out-of-Bag Error
<ul>
<li>A free method for estimating the test error.</li>
<li>Uses observations not included in the bootstrap sample to predict their values.</li>
<li>Provides an estimate of leave-one-out cross-validation.</li>
</ul></li>
<li>Random Forests
<ul>
<li>An extension of bagging that further reduces correlation between trees.</li>
<li>At each split, only a random subset of predictors is considered.</li>
<li>Improves prediction accuracy over bagging.</li>
</ul></li>
<li>Example: Heart Data
<ul>
<li>Compares the performance of bagging and random forests on the heart data.</li>
<li>Shows that random forests can slightly improve prediction accuracy over bagging.</li>
</ul></li>
<li>Example: Gene Expression Data
<ul>
<li>Applies random forests to a high-dimensional gene expression dataset.</li>
<li>Demonstrates the effectiveness of random forests in classifying cancer types.</li>
<li>Highlights the importance of pre-screening genes using variance.</li>
</ul></li>
<li>Conclusion
<ul>
<li>Bagging and random forests are powerful methods for improving tree-based predictions.</li>
<li>They are widely used in various applications.</li>
<li>Out-of-bag error provides a convenient way to estimate test error.</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div class="no-row-height column-margin column-container"><div id="fig-8.4" class="quarto-float quarto-figure quarto-figure-center anchored callout-5-contents callout-collapse collapse show callout-margin-content">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-8.4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/_cKAxjnInfA?list=PLoROMvodv4rPP6braWoRt5UCXYZ71GZIQ" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-8.4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Bagging
</figcaption>
</figure>
</div></div><div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Boosting
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">

<p>Outline of fifth video</p>
<p>Statistical Learning: 8.5 Boosting</p>
<ul>
<li>Boosting
<ul>
<li>Sequential method</li>
<li>Builds on previous trees to improve performance</li>
<li>Fits trees to residuals</li>
<li>Shrinks trees to avoid overfitting</li>
<li>Effective with smaller trees</li>
</ul></li>
<li>Tuning Parameters
<ul>
<li>Depth of the tree (d)
<ul>
<li>d=1: stump (single split)</li>
<li>Larger d: allows interactions between predictors</li>
</ul></li>
<li>Number of trees (B)
<ul>
<li>Typically not a critical parameter</li>
</ul></li>
<li>Shrinkage parameter (lambda)
<ul>
<li>Controls the amount each tree is added to the model</li>
</ul></li>
</ul></li>
<li>Variable Importance
<ul>
<li>Measures the total drop in RSS for a given predictor over all splits in the tree</li>
<li>Provides a qualitative ranking of variable importance</li>
</ul></li>
<li>Summary
<ul>
<li>Ensembles of trees can improve prediction accuracy</li>
<li>Random forests and boosting are state-of-the-art techniques for supervised learning</li>
<li>Interpretation can be more challenging with ensembles</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div class="no-row-height column-margin column-container"><div id="fig-8.5" class="quarto-float quarto-figure quarto-figure-center anchored callout-6-contents callout-collapse collapse show callout-margin-content">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-8.5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/cdl4C2eCOHk?list=PLoROMvodv4rPP6braWoRt5UCXYZ71GZIQ" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-8.5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: Boosting
</figcaption>
</figure>
</div></div><div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
BART - Bayesian Additive Regression Trees
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">

<p>Outline of sixth video</p>
<ul>
<li><p>Introduction</p>
<ul>
<li>What is BART?</li>
<li>Ensemble method using decision trees as building blocks</li>
<li>Similar to random forests and boosting</li>
</ul></li>
<li><p>BART Algorithm:</p>
<ul>
<li><p>Number of Trees (k): Determines the number of trees in the ensemble.</p></li>
<li><p>Number of Iterations (b): Controls the number of times each tree is perturbed.</p></li>
<li><p>Perturbations:</p>
<ul>
<li><p>Adding branches</p></li>
<li><p>Deleting branches</p></li>
<li><p>Changing predicted values at terminal nodes</p></li>
</ul></li>
<li><p>Prediction: Averaging predictions from all trees and iterations after a burn-in period.</p></li>
</ul></li>
<li><p>Comparison with Other Methods</p>
<ul>
<li>Bagging and Random Forests: Similar in using random samples to build trees.</li>
<li>Boosting: Similar in using residuals to guide tree construction.</li>
<li>Differences: BART uses perturbations to modify existing trees instead of building new trees from scratch.</li>
<li>Chain Monte Carlo (MCMC) method</li>
</ul></li>
<li><p>Example: Heart Data</p>
<ul>
<li>Compare BART with boosting and random forest</li>
<li>BART shows slower training error but competitive test error</li>
<li>Less prone to overfitting than boosting</li>
<li>Choosing Parameters
<ul>
<li>Number of trees (k)</li>
<li>Number of iterations (b)</li>
<li>Burn-in period (l)</li>
</ul></li>
<li>Reasonable choices: k = 200, b = 1000, l = 100</li>
</ul></li>
<li><p>Advantages of BART</p>
<ul>
<li>Works well out-of-the-box without much tuning</li>
<li>Provides uncertainty estimates (quantiles)</li>
</ul></li>
<li><p>Conclusion</p>
<ul>
<li>BART is a powerful ensemble method for regression</li>
<li>Combines features of random forests and boosting</li>
<li>Provides a flexible and robust approach to regression problems</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div class="no-row-height column-margin column-container"><div id="fig-8.6" class="quarto-float quarto-figure quarto-figure-center anchored callout-7-contents callout-collapse collapse show callout-margin-content">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-8.6-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/xWhPwHZF4c0?list=PLoROMvodv4rPP6braWoRt5UCXYZ71GZIQ" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-8.6-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: BART: Bayesian Additive Regression Trees
</figcaption>
</figure>
</div></div><div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Python lab on Tree-Based Methods
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">

<p>Outline of seventh video</p>
<ul>
<li>Introduction:
<ul>
<li>Overview of tree-based methods</li>
<li>Focus on random forest and boosting</li>
<li>Introduction of single tree-based method</li>
</ul></li>
<li>Imports:
<ul>
<li>Import necessary libraries</li>
</ul></li>
<li>Decision Tree Regression
<ul>
<li>Fitting a regression decision tree</li>
<li>Data set: Boston data set</li>
<li>Pre-processing: feature selection</li>
<li>Validation: split data into training and test sets</li>
<li>Visualizing the decision tree</li>
<li>Evaluating accuracy: mean squared error</li>
</ul></li>
<li>Ensemble Methods:
<ul>
<li>Bagging and Random Forest</li>
<li>Difference between bagging and random forest</li>
<li>Fitting a random forest regressor</li>
<li>Evaluating accuracy</li>
<li>Increasing the number of trees</li>
<li>Feature importance</li>
</ul></li>
<li>Boosting:
<ul>
<li>Difference between boosting and random forest</li>
<li>Fitting a boosting regressor</li>
<li>Evaluating accuracy</li>
<li>Plotting training and test error</li>
<li>Tuning parameters</li>
</ul></li>
<li>Conclusion:
<ul>
<li>Summary of tree-based methods</li>
<li>Comparison of random forest and boosting</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div class="no-row-height column-margin column-container"><div id="fig-8.7" class="quarto-float quarto-figure quarto-figure-center anchored callout-8-contents callout-collapse collapse show callout-margin-content">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-8.7-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/AVTfC5WnDTo?list=PLoROMvodv4rPP6braWoRt5UCXYZ71GZIQ" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-8.7-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: Python lab on Tree-Based Methods
</figcaption>
</figure>
</div></div><section id="slides-and-chapter" class="level2">
<h2 class="anchored" data-anchor-id="slides-and-chapter">Slides and Chapter</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slides.pdf" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Chapter Slides"><embed src="slides.pdf" class="col-page" style="width:5in;height:3.8in"></a></p>
<figcaption>Chapter Slides</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="ch08.pdf" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Chapter"><embed src="ch08.pdf" class="col-page" width="800" height="1000"></a></p>
<figcaption>Chapter</figcaption>
</figure>
</div>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div>CC SA BY-NC-ND</div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2024,
  author = {Bochman, Oren},
  title = {Chapter 8: {Trees}},
  date = {2024-08-01},
  url = {https://orenbochman.github.io/notes-islr/posts/ch08-tree-based-methods/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2024" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2024. <span>“Chapter 8: Trees.”</span> August 1, 2024. <a href="https://orenbochman.github.io/notes-islr/posts/ch08-tree-based-methods/">https://orenbochman.github.io/notes-islr/posts/ch08-tree-based-methods/</a>.
</div></div></section></div> ]]></description>
  <category>notes</category>
  <category>edx</category>
  <guid>https://orenbochman.github.io/notes-islr/posts/ch08-tree-based-methods/</guid>
  <pubDate>Wed, 31 Jul 2024 21:00:00 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/notes-islr/images/nlp-brain-wordcloud.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Chapter 7: Moving Beyond Linearity</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/notes-islr/posts/ch07-beyond-linearity/</link>
  <description><![CDATA[ 






<div class="no-row-height column-margin column-container"><div id="fig-v1.1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v1.1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/LvySJGj-88U?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v1.1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Opening Remarks
</figcaption>
</figure>
</div><div id="fig-v1.2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v1.2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/B9s8rpdNxU0?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v1.2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Examples and Framework
</figcaption>
</figure>
</div></div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
TL;DR - Beyond Linearity
</div>
</div>
<div class="callout-body-container callout-body">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="../../images/in_a_nutshell.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Beyond Linearity in a nutshell"><img src="https://orenbochman.github.io/notes-islr/images/in_a_nutshell.jpg" class="img-fluid figure-img" alt="Beyond Linearity in a nutshell"></a></p>
<figcaption>Beyond Linearity in a nutshell</figcaption>
</figure>
</div>
<audio controls="1">
<source src="podcast.mp3" data-external="1" type="audio/mpeg">

</audio>
</div>
</div>
<section id="slides-and-chapter" class="level2">
<h2 class="anchored" data-anchor-id="slides-and-chapter">Slides and Chapter</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slides.pdf" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Chapter Slides"><embed src="slides.pdf" class="col-page" style="width:5in;height:3.8in"></a></p>
<figcaption>Chapter Slides</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="ch07.pdf" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Chapter"><embed src="ch07.pdf" class="col-page" width="800" height="1000"></a></p>
<figcaption>Chapter</figcaption>
</figure>
</div>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div>CC SA BY-NC-ND</div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2024,
  author = {Bochman, Oren},
  title = {Chapter 7: {Moving} {Beyond} {Linearity}},
  date = {2024-07-28},
  url = {https://orenbochman.github.io/notes-islr/posts/ch07-beyond-linearity/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2024" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2024. <span>“Chapter 7: Moving Beyond Linearity.”</span>
July 28, 2024. <a href="https://orenbochman.github.io/notes-islr/posts/ch07-beyond-linearity/">https://orenbochman.github.io/notes-islr/posts/ch07-beyond-linearity/</a>.
</div></div></section></div> ]]></description>
  <category>notes</category>
  <category>edx</category>
  <guid>https://orenbochman.github.io/notes-islr/posts/ch07-beyond-linearity/</guid>
  <pubDate>Sat, 27 Jul 2024 21:00:00 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/notes-islr/images/nlp-brain-wordcloud.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Chapter 6: Linear Model Selection and Regularization</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/notes-islr/posts/ch06-model-selection-and-regularization/</link>
  <description><![CDATA[ 






<div class="no-row-height column-margin column-container"><div id="fig-v6.1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v6.1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/nsv5rEV3mVI?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v6.1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Introduction and Best Subset Selection
</figcaption>
</figure>
</div><div id="fig-v6.2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v6.2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/ynXq-Gw1xfE?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v6.2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Stepwise Selection
</figcaption>
</figure>
</div><div id="fig-v6.3" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v6.3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/c5aI9cowjRI?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v6.3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Backward stepwise selection
</figcaption>
</figure>
</div><div id="fig-v6.4" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v6.4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/48P-oV6cH44?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v6.4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Estimating test error
</figcaption>
</figure>
</div><div id="fig-v6.5" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v6.5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/mzb5Xs58bb0?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v6.5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: Validation and cross validation
</figcaption>
</figure>
</div><div id="fig-v6.6" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v6.6-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/lLlG5xkyqIA?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v6.6-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: Shrinkage methods and ridge regression
</figcaption>
</figure>
</div><div id="fig-v6.7" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v6.7-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/0tfPuddPhEY?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v6.7-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: The Lasso
</figcaption>
</figure>
</div><div id="fig-v6.8" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v6.8-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/KV1Kt6I8rYs?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v6.8-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8: Tuning parameter selection
</figcaption>
</figure>
</div><div id="fig-v6.9" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v6.9-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/bpto4g5l_go?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v6.9-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9: Dimension Reduction Methods
</figcaption>
</figure>
</div><div id="fig-v6.10" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v6.10-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/Uo19ST0IEZI?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v6.10-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10: Principal Components Regression and Partial Least Squares
</figcaption>
</figure>
</div></div>








<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
TL;DR - Linear Model Selection and Regularization
</div>
</div>
<div class="callout-body-container callout-body">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="../../images/in_a_nutshell.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Model Selection and Regularization in a nutshell"><img src="https://orenbochman.github.io/notes-islr/images/in_a_nutshell.jpg" class="img-fluid figure-img" alt="Model Selection and Regularization in a nutshell"></a></p>
<figcaption>Model Selection and Regularization in a nutshell</figcaption>
</figure>
</div>
<p>We cover four main topics in this chapter:</p>
<ol type="1">
<li>Model selection is the process of choosing the best model from a set of candidate models. It involves evaluating trade-offs between model complexity (number of predictors) and model fit (accuracy).</li>
<li>Shrinkage Methods are techniques that constrain or regularize coefficient estimates, effectively shrinking them towards zero. This helps reduce variance and improve prediction accuracy, particularly in high-dimensional datasets. Regularization techniques, such as ridge regression and lasso, help control overfitting by shrinking coefficient estimates towards zero.</li>
<li>Dimension Reduction Methods like principal component regression and partial least squares, reduce the number of predictors used in a model, thus simplifying it and potentially improving performance. Understanding the bias-variance trade-off is essential for selecting the appropriate level of model complexity and regularization.</li>
<li>Cross-validation is a powerful tool for selecting tuning parameters and comparing different models.</li>
</ol>
<audio controls="1">
<source src="podcast.mp3" data-external="1" type="audio/mpeg">

</audio>
</div>
</div>
<section id="terminology-for-model-selection-and-regularization" class="level2">
<h2 class="anchored" data-anchor-id="terminology-for-model-selection-and-regularization">Terminology for Model Selection and Regularization</h2>
<dl>
<dt>Best Subset Selection</dt>
<dd>
A method that evaluates all possible subsets of predictor variables to find the model with the lowest training error.
</dd>
</dl>
<p><a href="alg6.1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="https://orenbochman.github.io/notes-islr/posts/ch06-model-selection-and-regularization/alg6.1.png" class="img-fluid"></a></p>
<dl>
<dt>Forward Stepwise Selection</dt>
<dd>
A method that starts with an empty model and iteratively adds the predictor that most improves the model fit at each step.
</dd>
</dl>
<p><a href="alg6.2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="https://orenbochman.github.io/notes-islr/posts/ch06-model-selection-and-regularization/alg6.2.png" class="img-fluid"></a></p>
<dl>
<dt>Backward Stepwise Selection</dt>
<dd>
A method that starts with a model containing all predictors and iteratively removes the least significant predictor at each step.
</dd>
</dl>
<p><a href="alg6.3.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="https://orenbochman.github.io/notes-islr/posts/ch06-model-selection-and-regularization/alg6.3.png" class="img-fluid"></a></p>
<dl>
<dt>Mallow’s Cp</dt>
<dd>
A statistic used to assess the fit of a model, taking into account both the residual sum of squares and the number of parameters.
</dd>
<dt>Akaike Information Criterion (AIC)</dt>
<dd>
A metric that estimates prediction error and balances model complexity with goodness of fit, favoring simpler models.
</dd>
<dt>Bayesian Information Criterion (BIC)</dt>
<dd>
A similar metric to AIC but with a stronger penalty for model complexity, leading to even simpler models.
</dd>
<dt>Ridge Regression</dt>
<dd>
A shrinkage method that adds an L2 penalty to the least squares objective function, shrinking coefficients towards zero and reducing variance.
</dd>
<dt>Lasso</dt>
<dd>
A shrinkage method that uses an L1 penalty, forcing some coefficients to become exactly zero, leading to variable selection.
</dd>
<dt>Tuning Parameter (λ)</dt>
<dd>
A parameter that controls the strength of the penalty in shrinkage methods, balancing model fit with coefficient shrinkage.
</dd>
<dt>Cross-Validation</dt>
<dd>
A resampling technique used to estimate the performance of a model on unseen data and to select tuning parameters.
</dd>
<dt>Principal Component Regression (PCR)</dt>
<dd>
A dimension reduction technique that uses principal components (linear combinations of predictors capturing maximum variance) as predictors in regression.
</dd>
<dt>Partial Least Squares (PLS)</dt>
<dd>
A dimension reduction method that constructs components that maximize the covariance between the predictors and the response, aiming for better prediction performance.
</dd>
<dt>Multicollinearity</dt>
<dd>
A situation where predictor variables are highly correlated, which can lead to unstable coefficient estimates in least squares regression.
</dd>
<dt>Bias-Variance Trade-off</dt>
<dd>
The fundamental trade-off between model complexity and prediction accuracy. Simpler models have higher bias but lower variance, while complex models have lower bias but higher variance.
</dd>
<dt>Sparsity</dt>
<dd>
A property of a model where many of the coefficient estimates are exactly zero, indicating that only a subset of the predictors is used in the model.
</dd>
<dt>L1 Norm</dt>
<dd>
The sum of the absolute values of the elements of a vector.
</dd>
<dt>L2 Norm</dt>
<dd>
The square root of the sum of squared elements of a vector.
</dd>
</dl>
</section>
<section id="outline-of-chapter-6" class="level2">
<h2 class="anchored" data-anchor-id="outline-of-chapter-6">Outline of Chapter 6</h2>
</section>
<section id="important-concepts" class="level2">
<h2 class="anchored" data-anchor-id="important-concepts">Important Concepts:</h2>
<ol type="1">
<li><p>Subset Selection Methods:</p>
<ul>
<li><strong>Best Subset Selection</strong>: Evaluates all possible combinations of predictors, choosing the model with the lowest RSS (residual sum of squares) or highest R-squared. Computationally expensive for large datasets.</li>
<li><strong>Forward Stepwise Selection</strong>: Starts with a null model and iteratively adds the predictor that most improves the model fit. Continues until all predictors are included or a stopping criterion is met.</li>
<li><strong>Backward Stepwise Selection</strong>: Starts with the full model and iteratively removes the least useful predictor. Continues until a stopping criterion is met.</li>
<li>Challenges: Selecting the optimal model size requires metrics that estimate test error.</li>
<li>Common Metrics:
<ul>
<li><strong>Mallow’s <img src="https://latex.codecogs.com/png.latex?C_p"></strong>: Estimates test MSE (mean squared error) based on training RSS and model complexity. Seeks models with low Cp.</li>
</ul>
<blockquote class="blockquote">
<p>“Mallow’s Cp is sometimes defined as <img src="https://latex.codecogs.com/png.latex?C'_p%20=%20RSS/%5Chat%7B%5Csigma%7D%5E2%20+%202d%20-%20n">. This is equivalent to the definition given above in the sense that <img src="https://latex.codecogs.com/png.latex?Cp%20=%20%5Cfrac%7B1%7D%7Bn%7D%20%5Chat%7B%5Csigma%7D%5E2%20(C'_p%20+%20n)">, and so the model with smallest <img src="https://latex.codecogs.com/png.latex?C_p"> also has smallest <img src="https://latex.codecogs.com/png.latex?C'_p">.”</p>
</blockquote>
<ul>
<li><strong>AIC (Akaike Information Criterion)</strong>: Estimates test MSE using maximum likelihood and model complexity. Favors models with low AIC.</li>
</ul>
<blockquote class="blockquote">
<p>“The AIC criterion is defined for a large class of models fit by maximum likelihood: AIC = −2 logL+ 2 · d where L is the maximized value of the likelihood function for the estimated model.”</p>
</blockquote>
<ul>
<li><p><strong>BIC (Bayesian Information Criterion)</strong>: Similar to AIC but penalizes model complexity more heavily. Prefers simpler models with low BIC.</p></li>
<li><p><strong>Adjusted R-squared</strong>: Accounts for the number of predictors in the model. Higher adjusted R-squared indicates better fit.</p></li>
</ul></li>
<li>Cross-Validation: Directly estimates test error by splitting data into training and validation sets.</li>
</ul>
<blockquote class="blockquote">
<p>“This procedure has an advantage relative to AIC, BIC, Cp, and adjusted R2, in that it provides a direct estimate of the test error, and makes fewer assumptions about the true underlying model.”</p>
</blockquote></li>
<li><p>Shrinkage Methods:</p>
<ul>
<li>Ridge Regression: Shrinks coefficient estimates towards zero by adding a penalty term proportional to the sum of squared coefficients. All predictors are included in the final model.</li>
</ul>
<blockquote class="blockquote">
<p>“Ridge regression is very similar to least squares, except that the coefficients are estimated by minimizing a slightly different quantity.”</p>
</blockquote>
<blockquote class="blockquote">
<p>“The penalty <img src="https://latex.codecogs.com/png.latex?%5Clambda%20%5Csum%20%5Cbeta%5E2_j"> in (6.5) will shrink all of the coefficients towards zero, but it will not set any of them exactly to zero unless <img src="https://latex.codecogs.com/png.latex?%5Clambda%20=%20%5Cinfty">.”</p>
</blockquote>
<ul>
<li>Lasso (Least Absolute Shrinkage and Selection Operator): Shrinks coefficients by adding a penalty term proportional to the sum of absolute coefficient values. Forces some coefficients to be exactly zero, performing variable selection.</li>
</ul>
<blockquote class="blockquote">
<p>“The lasso is a relatively recent alternative to ridge regression that overcomes this disadvantage. The lasso coefficients, <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Cbeta%7D%5EL_%5Clambda">#, minimize the quantity…”</p>
</blockquote>
<blockquote class="blockquote">
<p>“As with ridge regression, the lasso shrinks the coefficient estimates towards zero. However, in the case of the lasso, the %1 penalty has the effect of forcing some of the coefficient estimates to be exactly equal to zero when the tuning parameter ! is sufficiently large.”</p>
</blockquote>
<ul>
<li>Benefits: Both methods improve prediction accuracy by reducing variance, but Lasso provides more interpretable models due to variable selection.</li>
<li>Challenges: Selecting the optimal tuning parameter (λ or s). Cross-validation is widely used for this purpose.</li>
</ul></li>
<li><p>Dimension Reduction Methods:</p>
<ul>
<li><strong>Principal Component Regression</strong> (PCR): Constructs new variables (principal components) as linear combinations of original predictors, capturing most of the variance. Regresses the response on a subset of these components.</li>
</ul>
<blockquote class="blockquote">
<p>“PCR identifies linear combinations, or directions, that best represent the predictors <img src="https://latex.codecogs.com/png.latex?X_1,%20%5Cldots%20,%20X_p.">”</p>
</blockquote>
<ul>
<li><strong>Partial Least Squares</strong> (PLS): Similar to PCR but constructs components that are also related to the response variable.</li>
<li>Benefits: Reduce dimensionality, potentially leading to improved prediction accuracy and model interpretability.</li>
<li>Challenges: Choosing the number of components to retain. Cross-validation can be used to determine this.</li>
</ul></li>
</ol>
</section>
<section id="important-considerations-in-high-dimensions" class="level2">
<h2 class="anchored" data-anchor-id="important-considerations-in-high-dimensions">Important Considerations in High Dimensions:</h2>
<p>Traditional methods can struggle with high-dimensional data (p &gt; n). Regularization techniques become crucial for controlling variance and preventing overfitting. Computational efficiency is essential for handling large datasets. Key Takeaways:</p>
<p>Choosing the right method depends on the specific dataset and the goal of the analysis. Understanding the bias-variance trade-off is essential for selecting the appropriate level of model complexity and regularization. Cross-validation is a powerful tool for selecting tuning parameters and comparing different models. Further Research:</p>
<p>Explore different cross-validation strategies and their performance with various model types. Investigate the theoretical properties and limitations of different model selection and regularization methods. Apply these techniques to real-world datasets and evaluate their effectiveness in practice.</p>
</section>
<section id="slides-and-chapter" class="level2">
<h2 class="anchored" data-anchor-id="slides-and-chapter">Slides and Chapter</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slides.pdf" class="lightbox" data-gallery="quarto-lightbox-gallery-5" title="Chapter Slides"><embed src="slides.pdf" class="col-page" style="width:5in;height:3.8in"></a></p>
<figcaption>Chapter Slides</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="ch06.pdf" class="lightbox" data-gallery="quarto-lightbox-gallery-6" title="Chapter"><embed src="ch06.pdf" class="col-page" width="800" height="1000"></a></p>
<figcaption>Chapter</figcaption>
</figure>
</div>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div>CC SA BY-NC-ND</div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2024,
  author = {Bochman, Oren},
  title = {Chapter 6: {Linear} {Model} {Selection} and {Regularization}},
  date = {2024-07-20},
  url = {https://orenbochman.github.io/notes-islr/posts/ch06-model-selection-and-regularization/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2024" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2024. <span>“Chapter 6: Linear Model Selection and
Regularization.”</span> July 20, 2024. <a href="https://orenbochman.github.io/notes-islr/posts/ch06-model-selection-and-regularization/">https://orenbochman.github.io/notes-islr/posts/ch06-model-selection-and-regularization/</a>.
</div></div></section></div> ]]></description>
  <category>notes</category>
  <category>edx</category>
  <category>podcast</category>
  <guid>https://orenbochman.github.io/notes-islr/posts/ch06-model-selection-and-regularization/</guid>
  <pubDate>Fri, 19 Jul 2024 21:00:00 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/notes-islr/images/nlp-brain-wordcloud.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Chapter 5: Resampling Methods</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/notes-islr/posts/ch05-resampling-methods/</link>
  <description><![CDATA[ 






<div class="no-row-height column-margin column-container"><div id="fig-v5.1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v5.1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/6eWODQJrMKs?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v5.1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Cross Validation
</figcaption>
</figure>
</div><div id="fig-v5.2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v5.2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/AMfvd_hLssE?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v5.2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: K-fold Cross Validation
</figcaption>
</figure>
</div><div id="fig-v5.3" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v5.3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/jgoa28FR__Y?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v5.3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Cross Validation the wrong and right way
</figcaption>
</figure>
</div><div id="fig-5.4" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-5.4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/h_LweqiIotE?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-5.4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: K-fold Cross Validation
</figcaption>
</figure>
</div><div id="fig-5.5" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-5.5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/AMfvd_hLssE?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-5.5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: More on the Bootstrap
</figcaption>
</figure>
</div><div id="fig-5.6" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-5.6-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/nwD-03ncOZ8?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-5.6-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: Lab: Cross Validation
</figcaption>
</figure>
</div><div id="fig-5.7" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-5.7-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/sM_Gve1K4II?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-5.7-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: Lab: Bootstrap
</figcaption>
</figure>
</div></div>





<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
TL;DR - Resampling Methods
</div>
</div>
<div class="callout-body-container callout-body">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="../../images/in_a_nutshell.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Resampling Methods in a nutshell"><img src="https://orenbochman.github.io/notes-islr/images/in_a_nutshell.jpg" class="img-fluid figure-img" alt="Resampling Methods in a nutshell"></a></p>
<figcaption>Resampling Methods in a nutshell</figcaption>
</figure>
</div>
<p>Resampling methods are indispensable tools for data scientists. Cross-validation and the bootstrap empower us to evaluate model performance, estimate uncertainties, and ultimately make more informed decisions based on our statistical learning models.</p>
<blockquote class="blockquote">
<p>“The bootstrap is a flexible and powerful statistical tool that can be used to quantify the uncertainty associated with a given estimator or statistical learning method.”</p>
</blockquote>
<blockquote class="blockquote">
<p>“LOOCV sometimes useful, but typically doesn’t shake up the data enough. The estimates from each fold are highly correlated and hence their average can have high variance.”</p>
</blockquote>
<blockquote class="blockquote">
<p>“In cross-validation, each of the K validation folds is distinct from the other K − 1 folds used for training: there is no overlap. This is crucial for its success.”</p>
</blockquote>
<audio controls="1">
<source src="podcast.mp3" data-external="1" type="audio/mpeg">

</audio>
</div>
</div>
<section id="summary-of-resampling-methods" class="level2">
<h2 class="anchored" data-anchor-id="summary-of-resampling-methods">Summary of Resampling Methods</h2>
<p>In this chapter we focus on resampling methods, specifically focusing on cross-validation and the bootstrap.</p>
<p>Central Theme: Resampling methods offer robust techniques to estimate the performance of statistical learning methods and quantify uncertainty associated with estimations. This is achieved by repeatedly drawing samples from the training data and refitting models on these samples.</p>
<p>Key Concepts and Methods</p>
<ol type="1">
<li><strong>Validation Set Approach</strong>: This approach involves splitting the dataset into a training set and a validation set. The model is trained on the training set, and its performance (e.g., using MSE for regression problems) is evaluated on the validation set.</li>
</ol>
<ul>
<li>Drawbacks:
<ul>
<li>High variability in test error estimates depending on the random split.</li>
<li>Reduced sample size for training as only the training set is used.</li>
<li>Example: Using the Auto dataset, the sources demonstrate that a quadratic fit performs better than a linear fit for predicting ‘mpg’ based on ‘horsepower’.</li>
</ul></li>
</ul>
<ol type="1">
<li><strong>Cross-Validation</strong>: addresses the limitations of the validation set approach. It involves dividing the data into ‘K’ folds and iteratively using one fold for validation and the rest for training. This provides more stable performance estimates.
<ul>
<li>Leave-One-Out Cross-Validation (LOOCV): A special case where K equals the number of observations. Each observation is held out once for validation.
<ul>
<li>Benefits: Less bias in test error estimates.</li>
<li>Drawbacks: High variance due to high correlation between the training sets.</li>
</ul></li>
<li>k-Fold Cross-Validation: A more general approach where K is typically 5 or 10, balancing bias and variance.
<ul>
<li>Example: Using the Auto dataset, k-fold cross-validation confirms the superiority of the quadratic fit over the linear fit.</li>
</ul></li>
</ul></li>
<li><strong>The Bootstrap</strong>: is used to quantify uncertainty in an estimator. It involves generating multiple ‘bootstrap’ datasets by sampling with replacement from the original data. The statistic of interest is calculated for each bootstrap dataset, creating a distribution from which standard errors and confidence intervals can be derived.
<ul>
<li>Example: Simulating investment returns for assets X and Y, the sources illustrate how the bootstrap can be used to estimate the standard error of the optimal investment allocation (α).</li>
</ul></li>
<li><strong>Bootstrap Applications</strong>:
<ul>
<li><strong>Estimating Standard Errors</strong>: The bootstrap provides an alternative way to calculate standard errors for complex estimators where analytical formulas may not be available.</li>
<li><strong>Confidence Intervals</strong>: Approximate confidence intervals can be derived from the distribution of bootstrap estimates.</li>
<li><strong>Prediction Error Estimation</strong>: While the bootstrap is mainly used for standard error and confidence interval calculations, it’s not ideal for directly estimating prediction error due to the overlap in training data between bootstrap samples.</li>
</ul></li>
</ol>
</section>
<section id="important-considerations" class="level2">
<h2 class="anchored" data-anchor-id="important-considerations">Important Considerations</h2>
<ul>
<li>Cross-validation for classification: When dealing with classification problems, the metric used for evaluating performance is typically the misclassification rate instead of MSE.</li>
<li>Choosing K: The choice of K in k-fold cross-validation involves a bias-variance trade-off. K = 5 or K = 10 generally provides a good balance.</li>
<li>Pre-validation: This technique is specifically designed for comparing adaptively derived predictors with fixed predictors by creating a ‘fairer’ version of the adaptive predictor that hasn’t ‘seen’ the response variable.</li>
<li>Bootstrap Sampling: The way bootstrap samples are generated needs careful consideration depending on the data structure. For instance, in time series data, blocks of consecutive observations are sampled instead of individual observations to preserve the temporal correlation.</li>
</ul>
<p>Conclusion: Resampling methods are indispensable tools for data scientists. Cross-validation and the bootstrap empower us to evaluate model performance, estimate uncertainties, and ultimately make more informed decisions based on our statistical learning models.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slides.pdf" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Chapter Slides"><embed src="slides.pdf" class="col-page" style="width:5in;height:3.8in"></a></p>
<figcaption>Chapter Slides</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="ch05.pdf" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Chapter"><embed src="ch05.pdf" class="col-page" width="800" height="1000"></a></p>
<figcaption>Chapter</figcaption>
</figure>
</div>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div>CC SA BY-NC-ND</div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2024,
  author = {Bochman, Oren},
  title = {Chapter 5: {Resampling} {Methods}},
  date = {2024-07-10},
  url = {https://orenbochman.github.io/notes-islr/posts/ch05-resampling-methods/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2024" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2024. <span>“Chapter 5: Resampling Methods.”</span> July
10, 2024. <a href="https://orenbochman.github.io/notes-islr/posts/ch05-resampling-methods/">https://orenbochman.github.io/notes-islr/posts/ch05-resampling-methods/</a>.
</div></div></section></div> ]]></description>
  <category>notes</category>
  <category>edx</category>
  <category>podcast</category>
  <guid>https://orenbochman.github.io/notes-islr/posts/ch05-resampling-methods/</guid>
  <pubDate>Tue, 09 Jul 2024 21:00:00 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/notes-islr/images/nlp-brain-wordcloud.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Chapter 4: Classification</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/notes-islr/posts/ch04-classification/</link>
  <description><![CDATA[ 






<div class="no-row-height column-margin column-container"><div id="fig-v4.1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v4.1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/ju3J7iRy6xI?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v4.1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Introduction to Classification Problems
</figcaption>
</figure>
</div><div id="fig-v4.2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v4.2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/kr_Be9NVXOM?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v4.2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Logistic Regression
</figcaption>
</figure>
</div><div id="fig-v4.3" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v4.3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/1uJVE8bkabc?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v4.3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Multivariate Logistic Regression
</figcaption>
</figure>
</div><div id="fig-v4.4" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v4.4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/sYDDk6R-be0?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v4.4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Logistic Regression Case Control Sampling and Multiclass
</figcaption>
</figure>
</div><div id="fig-v4.5" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v4.5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/oJc2r246VoQ?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v4.5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: Discriminant Analysis
</figcaption>
</figure>
</div><div id="fig-v4.6" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v4.6-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/14JVlzWHKgk?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v4.6-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: Gaussian Discriminant Analysis (One Variable)
</figcaption>
</figure>
</div><div id="fig-v4.7" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v4.7-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/aUlTqhDtpnw?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v4.7-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: Gaussian Discriminant Analysis (Many Variables)
</figcaption>
</figure>
</div><div id="fig-v4.8" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v4.8-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/n8Nj64FyjSo?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v4.8-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8: Generalized Linear Models
</figcaption>
</figure>
</div><div id="fig-v4.9" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v4.9-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/giCZkipHEmA?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v4.9-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9: Quadratic Discriminant Analysis and Naive Bayes
</figcaption>
</figure>
</div><div id="fig-v4.10" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v4.10-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/QEUtuHSipNE?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v4.10-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10: R Lab: Logistic Regression
</figcaption>
</figure>
</div><div id="fig-v4.11" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v4.11-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/WXhku-ISml8?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v4.11-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11: R Lab: Linear Discriminant Analysis
</figcaption>
</figure>
</div><div id="fig-v4.11" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v4.11-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/JRxKBj5ArgU?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v4.11-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12: R Lab: Nearest Neighbor Classification
</figcaption>
</figure>
</div></div>










<p>The chapter is 65 pages long and covers the following topics:</p>
<ul>
<li>Classification
<ul>
<li>An Overview of Classification</li>
<li>Why Not Linear Regression?</li>
<li>Logistic Regression
<ul>
<li>The Logistic Model</li>
<li>Estimating the Regression Coefficients</li>
<li>Making Predictions</li>
<li>Multiple Logistic Regression</li>
<li>Multinomial Logistic Regression</li>
</ul></li>
<li>Generative Models for Classification
<ul>
<li>Linear Discriminant Analysis</li>
<li>Quadratic Discriminant Analysis</li>
<li>Naive Bayes</li>
</ul></li>
<li>A Comparison of Classification Methods
<ul>
<li>An Analytical Comparison</li>
<li>An Empirical Comparison</li>
</ul></li>
<li>Generalized Linear Models
<ul>
<li>Linear Regression on the Bikeshare Data</li>
<li>Poisson Regression on the Bikeshare Data</li>
<li>Generalized Linear Models in Greater Generality</li>
</ul></li>
<li>Lab: Logistic Regression, LDA, QDA, and KNN</li>
</ul></li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
TL;DR - Statistical Learning in a Nutshell
</div>
</div>
<div class="callout-body-container callout-body">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="../../images/in_a_nutshell.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Statistical Learning in a nutshell"><img src="https://orenbochman.github.io/notes-islr/images/in_a_nutshell.jpg" class="img-fluid figure-img" alt="Statistical Learning in a nutshell"></a></p>
<figcaption>Statistical Learning in a nutshell</figcaption>
</figure>
</div>
<p>Statistical learning is a set of tools for understanding data and building models that can be used for prediction or inference. The fundamental goal is to learn a function <img src="https://latex.codecogs.com/png.latex?(f)"> that captures the relationship between input variables (predictors) and an output variable (response). This learned function can then be used to make predictions for new observations or for inference i.e.&nbsp;to understand the underlying relationship between the variables.</p>
<audio controls="1">
<source src="podcast.mp3" data-external="1" type="audio/mpeg">

</audio>
</div>
</div>
<section id="glossary-of-key-terms" class="level2">
<h2 class="anchored" data-anchor-id="glossary-of-key-terms">Glossary of Key Terms</h2>
<dl>
<dt>Classification</dt>
<dd>
The task of predicting a categorical response variable based on a set of predictor variables.
</dd>
<dt>Qualitative Variable</dt>
<dd>
A variable that takes values in an unordered set of categories.
</dd>
<dt>Logistic Regression</dt>
<dd>
A classification method that models the probability of belonging to a category using a logit transformation and a linear combination of predictor variables.
</dd>
<dt>Confounding</dt>
<dd>
A situation where the relationship between a predictor and the response is distorted by the presence of another variable.
</dd>
<dt>Bayes’ Theorem</dt>
<dd>
A mathematical formula that calculates the posterior probability of an event given prior knowledge and new evidence.
</dd>
<dt>Discriminant Analysis</dt>
<dd>
A classification method that uses Bayes’ theorem to classify observations based on the probability of belonging to each class, assuming that the predictor variables follow a certain probability distribution.
</dd>
<dt>LDA (Linear Discriminant Analysis)</dt>
<dd>
A type of discriminant analysis that assumes a common covariance matrix for all classes, resulting in linear decision boundaries.
</dd>
<dt>QDA (Quadratic Discriminant Analysis)</dt>
<dd>
A type of discriminant analysis that allows different covariance matrices for each class, resulting in quadratic decision boundaries.
</dd>
<dt>Naive Bayes</dt>
<dd>
A classification method that assumes conditional independence of predictor variables within each class.
</dd>
<dt>Generalized Linear Model (GLM)</dt>
<dd>
A statistical framework that extends linear regression by allowing for different response variable distributions and a link function that connects the linear predictor to the mean of the response.
</dd>
<dt>Overdispersion</dt>
<dd>
A situation in Poisson regression where the variance of the response variable is larger than the mean.
</dd>
<dt>ROC Curve (Receiver Operating Characteristic Curve)</dt>
<dd>
A graphical plot that illustrates the performance of a binary classifier by plotting the true positive rate against the false positive rate at various threshold settings.
</dd>
<dt>Generative Model</dt>
<dd>
A statistical model that learns the joint probability distribution of the input features and the output variable, allowing for the generation of new data points.
</dd>
<dt>Discriminative Model</dt>
<dd>
A statistical model that directly learns the decision boundary between classes without explicitly modeling the underlying data distribution.
</dd>
<dt>Curse of Dimensionality</dt>
<dd>
The phenomenon where the performance of machine learning algorithms degrades as the number of features increases due to data sparsity and increased computational complexity.
</dd>
</dl>
</section>
<section id="core-concepts" class="level2">
<h2 class="anchored" data-anchor-id="core-concepts">Core Concepts:</h2>
<p>Classification: The task of assigning input data (feature vectors) to specific categories (classes) based on learned patterns. This is contrasted with regression, which predicts continuous outcomes. Logistic Regression: A powerful algorithm for predicting the probability of a binary outcome. It models the log-odds of the outcome as a linear function of the predictors. Discriminant Analysis: A generative approach to classification that assumes data within each class follows a specific distribution, often a Gaussian distribution. Linear Discriminant Analysis (LDA): Assumes the same covariance matrix for all classes, leading to linear decision boundaries. Quadratic Discriminant Analysis (QDA): Allows different covariance matrices for each class, leading to more flexible (quadratic) decision boundaries. Naive Bayes: A simplified generative model that assumes conditional independence among predictors within each class. It’s computationally efficient and surprisingly effective, even when the independence assumption is violated. Generalized Linear Models (GLMs): A unified framework encompassing linear, logistic, and Poisson regression. They model the relationship between the response variable and predictors through a link function. Model Evaluation: Crucial for assessing the performance of classification models. Key metrics include accuracy, error rates (overall, false positive, false negative), and ROC curves. Important Ideas and Facts:</p>
<p>Classification vs.&nbsp;Regression: While both involve predicting an outcome based on input features, classification deals with discrete categories (e.g., spam/ham, default/no default), whereas regression predicts a continuous value (e.g., house price). Logistic Regression for Probability Prediction: Logistic regression is widely used for binary classification, as it outputs a probability between 0 and 1. The equation relating probability to predictors is: p(X) = e^(β0 + β1X) / (1 + e^(β0 + β1X)) LDA and QDA: Distributional Assumptions: LDA and QDA rely on the assumption that data within each class follows a multivariate Gaussian distribution. The difference lies in whether they assume a shared covariance matrix (LDA) or class-specific covariance matrices (QDA). Naive Bayes and Conditional Independence: Naive Bayes greatly simplifies the modeling of high-dimensional data by assuming features are independent within each class. While this assumption is often unrealistic, it leads to computational efficiency and can still yield good predictive performance. Generalized Additive Models and Naive Bayes: Naive Bayes can be viewed as a special case of generalized additive models (GAMs). Both allow for non-linear relationships between features and the response variable. Choice of Classification Method: The choice of the best classification method depends on factors like the nature of the data, the number of predictors, the distributional assumptions, and the computational constraints.</p>
</section>
<section id="illustrative-examples" class="level2">
<h2 class="anchored" data-anchor-id="illustrative-examples">Illustrative Examples:</h2>
<p>Default Prediction: The “Default” dataset demonstrates logistic regression for predicting credit card default based on balance and student status. This example highlights the importance of interpreting model coefficients and evaluating performance metrics. South African Heart Disease: LDA is applied to predict the risk of myocardial infarction based on various risk factors. This illustrates the use of discriminant analysis for understanding the influence of predictors on a binary outcome. Bikeshare Data: This example explores the use of Poisson regression for modeling count data, showcasing its advantages over linear regression when the variance of the response is related to its mean. ## Key Quotes:</p>
<p>Classification: “Given a feature vector X and a qualitative response Y taking values in the set C, the classification task is to build a function C(X) that takes as input the feature vector X and predicts its value for Y” (Ch4_Classification.pdf) Logistic Regression: “The quantity p(X)/[1-p(X)] is called the odds, and can take on any value between 0 and ∞” (ch04.pdf). LDA Decision Boundary: “If there are K = 2 classes and π1 = π2 = 0.5, then one can see that the decision boundary is at x = (µ1 + µ2) / 2.” (Ch4_Classification.pdf) Naive Bayes Assumption: “Within the kth class, the p predictors are independent.” (ch04.pdf). GLMs: “Generalized linear models provide a unified framework for dealing with many different response types.” (Ch4_Classification.pdf) Conclusion:</p>
<p>Classification is a fundamental task in machine learning, with a variety of powerful algorithms at our disposal. Understanding the strengths and weaknesses of each method, along with their underlying assumptions, is essential for selecting the appropriate technique and interpreting the results effectively.</p>
</section>
<section id="slides-and-chapter" class="level2">
<h2 class="anchored" data-anchor-id="slides-and-chapter">Slides and Chapter</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slides.pdf" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Chapter Slides"><embed src="slides.pdf" class="col-page" style="width:5in;height:3.8in"></a></p>
<figcaption>Chapter Slides</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="ch04.pdf" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Chapter"><embed src="ch04.pdf" class="col-page" width="800" height="1000"></a></p>
<figcaption>Chapter</figcaption>
</figure>
</div>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div>CC SA BY-NC-ND</div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2024,
  author = {Bochman, Oren},
  title = {Chapter 4: {Classification}},
  date = {2024-07-01},
  url = {https://orenbochman.github.io/notes-islr/posts/ch04-classification/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2024" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2024. <span>“Chapter 4: Classification.”</span> July 1,
2024. <a href="https://orenbochman.github.io/notes-islr/posts/ch04-classification/">https://orenbochman.github.io/notes-islr/posts/ch04-classification/</a>.
</div></div></section></div> ]]></description>
  <category>notes</category>
  <category>edx</category>
  <category>podcast</category>
  <guid>https://orenbochman.github.io/notes-islr/posts/ch04-classification/</guid>
  <pubDate>Sun, 30 Jun 2024 21:00:00 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/notes-islr/images/nlp-brain-wordcloud.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Chapter 3: Linear Regression</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/notes-islr/posts/ch03-linear-regression/</link>
  <description><![CDATA[ 





<p>The lab for this chapter is at <a href="../../posts/ch03-linear-regression/Ch03-linreg-lab.html">lab</a> The chapter is 64 pages long and covers the following topics:</p>

<div class="no-row-height column-margin column-container"><div id="fig-v3.1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v3.1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/vCHtY6Me5FI?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v3.1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Simple linear regression
</figcaption>
</figure>
</div><div id="fig-v3.2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v3.2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/3GiWpRfkSjc?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v3.2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Hypothesis Testing and Confidence Intervals
</figcaption>
</figure>
</div><div id="fig-v3.3" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v3.3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/kr_Be9NVXOM&amp;list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v3.3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Multiple Linear Regression
</figcaption>
</figure>
</div><div id="fig-v3.4" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v3.4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/50sv4UTjE90?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v3.4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Some important questions
</figcaption>
</figure>
</div><div id="fig-v3.5" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v3.5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/dEBQmiXv9fk?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v3.5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: Extensions of the Linear Model
</figcaption>
</figure>
</div><div id="fig-v3.5" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v3.5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/gNZfqHhq_B4?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v3.5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: Regression in R
</figcaption>
</figure>
</div></div>




<ul>
<li>Linear Regression
<ul>
<li>Simple Linear Regression
<ul>
<li>Estimating the Coefficients</li>
<li>Assessing the Accuracy of the Coefficient Estimates</li>
<li>Assessing the Accuracy of the Model</li>
</ul></li>
<li>Multiple Linear Regression
<ul>
<li>Estimating the Regression Coefficients</li>
<li>Some Important Questions</li>
</ul></li>
<li>Other Considerations in the Regression Model
<ul>
<li>Qualitative Predictors</li>
<li>Extensions of the Linear Model</li>
<li>Potential Problems</li>
</ul></li>
<li>The Marketing Plan</li>
<li>Comparison of Linear Regression with K-Nearest Neighbors</li>
<li>Lab: Linear Regression</li>
</ul></li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
TL;DR - Linear Regression in a Nutshell
</div>
</div>
<div class="callout-body-container callout-body">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="../../images/in_a_nutshell.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Linear Regression in a nutshell"><img src="https://orenbochman.github.io/notes-islr/images/in_a_nutshell.jpg" class="img-fluid figure-img" alt="Linear Regression in a nutshell"></a></p>
<figcaption>Linear Regression in a nutshell</figcaption>
</figure>
</div>
<p>Linear regression is a fundamental statistical technique for modeling the relationship between a single predictor variable and a response variable. The model assumes a linear relationship between the predictor and the response, represented by a straight line. The goal is to estimate the coefficients of the model that minimize the difference between observed and predicted values. The accuracy of the model is assessed using metrics like the <strong>Residual Standard Error</strong> (RSE), adjusted <img src="https://latex.codecogs.com/png.latex?R%5E2">, <strong>F-statistic</strong>, and <strong>p-values</strong>. The coefficients are interpreted as the average change in the response for a one-unit increase in the predictor, holding all other variables constant. Qualitative predictors are incorporated using dummy variables, and interactions between predictors can capture complex relationships. Model diagnostics help identify potential issues like non-linearity, heteroscedasticity, outliers, high leverage points, and collinearity.</p>
</div>
</div>
<section id="linear-regression-summary" class="level2">
<h2 class="anchored" data-anchor-id="linear-regression-summary">Linear Regression Summary</h2>
<ol type="1">
<li><strong>Simple Linear Regression</strong>: Modeling the relationship between a single predictor variable and a response variable using a straight line.</li>
<li><strong>Multiple Linear Regression</strong>: Extending simple linear regression to accommodate multiple predictor variables.</li>
<li><strong>Model Assessment</strong>: Evaluating the accuracy and fit of linear regression models using metrics like <strong>RSE</strong>, <strong><img src="https://latex.codecogs.com/png.latex?R%5E2"></strong>, <strong>F-statistic</strong>, and <strong>p-values</strong>.</li>
<li><strong>Model Interpretation</strong>: Understanding the practical meaning of estimated coefficients and their significance in the context of the data.</li>
<li><strong>Qualitative Predictors</strong>: Incorporating categorical variables into regression models using dummy variables.</li>
<li><strong>Interactions</strong>: Modeling complex relationships by including interaction terms between predictors.</li>
<li><strong>Polynomial Regression</strong>: Capturing non-linear relationships using polynomial terms of predictor variables.</li>
<li><strong>Model Diagnostics</strong>: Identifying and addressing potential issues like non-linearity, heteroscedasticity, outliers, high leverage points, and collinearity.</li>
</ol>
</section>
<section id="simple-linear-regression" class="level2">
<h2 class="anchored" data-anchor-id="simple-linear-regression">Simple Linear Regression:</h2>
<ul>
<li><p><strong>Model</strong>: The relationship between response <img src="https://latex.codecogs.com/png.latex?(Y)"> and predictor <img src="https://latex.codecogs.com/png.latex?(X)"> is represented as <img src="https://latex.codecogs.com/png.latex?%0AY%20=%20%CE%B2_0%20+%20%CE%B2_1%20X%20+%20%5Cepsilon%0A"></p></li>
<li><p>where</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%CE%B2_0"> is the intercept,</li>
<li><img src="https://latex.codecogs.com/png.latex?%CE%B2_1"> is the slope, and</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cepsilon"> is the error term.</li>
</ul></li>
<li><p><strong>Least Squares Estimation</strong>: The coefficients <img src="https://latex.codecogs.com/png.latex?%CE%B2_0"> and <img src="https://latex.codecogs.com/png.latex?%CE%B2_1"> are estimated by minimizing the <strong>Residual Sum of Squares (RSS)</strong>, which quantifies the difference between observed and predicted values.</p></li>
<li><p><strong>Assessing Accuracy</strong>: The standard errors of the coefficients help construct confidence intervals and perform hypothesis tests to assess the significance of the relationship between <img src="https://latex.codecogs.com/png.latex?X"> and <img src="https://latex.codecogs.com/png.latex?Y">.</p></li>
<li><p><strong><img src="https://latex.codecogs.com/png.latex?R%5E2"></strong>: This statistic quantifies the proportion of variability in the response explained by the model, indicating how well the model fits the data.</p></li>
</ul>
</section>
<section id="multiple-linear-regression" class="level2">
<h2 class="anchored" data-anchor-id="multiple-linear-regression">Multiple Linear Regression:</h2>
<ul>
<li><p><strong>Model</strong>: The model extends to multiple predictors: <img src="https://latex.codecogs.com/png.latex?%0AY%20=%20%CE%B2_0%20+%20%CE%B2_1%20X_1%20+%20%CE%B2_2%20X_2%20+%20%5Cldots%20+%20%CE%B2_p%20X_p%20+%20%5Cepsilon%0A"></p></li>
<li><p><strong>Interpretation</strong>: Each coefficient <img src="https://latex.codecogs.com/png.latex?%CE%B2_j"> represents the average change in <img src="https://latex.codecogs.com/png.latex?Y"> for a one-unit increase in <img src="https://latex.codecogs.com/png.latex?X_j">, holding all other predictors constant.</p></li>
<li><p><strong>F-statistic</strong>: This statistic tests the overall significance of the model, determining whether at least one predictor is useful in predicting the response.</p></li>
<li><p><strong>Variable Selection</strong>: Techniques like <strong>Mallow’s Cp</strong>, <strong>AIC</strong>, <strong>BIC</strong>, and <strong>adjusted <img src="https://latex.codecogs.com/png.latex?R%5E2"></strong> are employed to choose the best subset of predictors for the model.</p></li>
</ul>
</section>
<section id="qualitative-predictors" class="level2">
<h2 class="anchored" data-anchor-id="qualitative-predictors">Qualitative Predictors:</h2>
<ul>
<li><strong>Dummy Variables</strong>: Categorical variables are incorporated by creating dummy variables, which take on values of 0 or 1 to represent different categories.</li>
<li><strong>Baseline Category</strong>: One category is chosen as the baseline, and its coefficient represents the average response for that category. Other dummy variable coefficients represent differences from the baseline.</li>
</ul>
</section>
<section id="interactions" class="level2">
<h2 class="anchored" data-anchor-id="interactions">Interactions:</h2>
<ul>
<li><strong>Interaction Terms</strong>: Including interaction terms like <img src="https://latex.codecogs.com/png.latex?X_1%20X_2"> in the model allows the relationship between one predictor and the response to vary depending on the value of another predictor.</li>
<li><strong>Synergy Effect</strong>: Interactions can capture synergistic effects where the combined impact of two predictors is greater than the sum of their individual impacts.</li>
</ul>
</section>
<section id="polynomial-regression" class="level2">
<h2 class="anchored" data-anchor-id="polynomial-regression">Polynomial Regression:</h2>
<ul>
<li><strong>Non-linear Relationships</strong>: Polynomial terms like <img src="https://latex.codecogs.com/png.latex?X%5E2"> are used to model non-linear relationships between predictors and the response.</li>
<li><strong>Overfitting</strong>: Higher-degree polynomials can lead to overfitting, where the model fits the training data too closely but generalizes poorly to new data.</li>
</ul>
</section>
<section id="model-diagnostics" class="level2">
<h2 class="anchored" data-anchor-id="model-diagnostics">Model Diagnostics:</h2>
<ul>
<li><strong>Residual Plots</strong>: Visualizing residuals against fitted values helps assess linearity, homoscedasticity, and the presence of outliers.</li>
<li><strong>High Leverage Points</strong>: Observations with extreme predictor values can have a disproportionate impact on the model and should be investigated.</li>
<li><strong>Collinearity</strong>: High correlation among predictors can lead to unstable coefficient estimates and inflated standard errors. <strong>VIF</strong> (Variance Inflation Factor) helps detect collinearity.</li>
</ul>
</section>
<section id="key-quotes" class="level2">
<h2 class="anchored" data-anchor-id="key-quotes">Key Quotes:</h2>
<blockquote class="blockquote">
<p>“The least squares approach chooses <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Cbeta%7D_0"> and <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Cbeta%7D_1"> to minimize the RSS.”</p>
</blockquote>
<blockquote class="blockquote">
<p>“We interpret <img src="https://latex.codecogs.com/png.latex?%CE%B2_j"> as the average effect on <img src="https://latex.codecogs.com/png.latex?Y"> of a one unit increase in <img src="https://latex.codecogs.com/png.latex?X_j"> , holding all other predictors fixed.”</p>
</blockquote>
<blockquote class="blockquote">
<p>“The woes of (interpreting) regression coefficients: … a regression coefficient <img src="https://latex.codecogs.com/png.latex?%CE%B2_j"> estimates the expected change in <img src="https://latex.codecogs.com/png.latex?Y"> per unit change in <img src="https://latex.codecogs.com/png.latex?X_j"> , with all other predictors held fixed. But predictors usually change together!”</p>
</blockquote>
<blockquote class="blockquote">
<p>“A 95% confidence interval is defined as a range of values such that with 95% probability, the range will contain the true unknown value of the parameter.”</p>
</blockquote>
<blockquote class="blockquote">
<p>“There will always be one fewer dummy variable than the number of levels. The level with no dummy variable — African American in this example — is known as the baseline.”</p>
</blockquote>
<blockquote class="blockquote">
<p>“When levels of either TV or radio are low, then the true sales are lower than predicted by the linear model. But when advertising is split between the two media, then the model tends to underestimate sales.”</p>
</blockquote>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis sagittis posuere ligula sit amet lacinia. Duis dignissim pellentesque magna, rhoncus congue sapien finibus mollis. Ut eu sem laoreet, vehicula ipsum in, convallis erat. Vestibulum magna sem, blandit pulvinar augue sit amet, auctor malesuada sapien. Nullam faucibus leo eget eros hendrerit, non laoreet ipsum lacinia. Curabitur cursus diam elit, non tempus ante volutpat a. Quisque hendrerit blandit purus non fringilla. Integer sit amet elit viverra ante dapibus semper. Vestibulum viverra rutrum enim, at luctus enim posuere eu. Orci varius natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus.</p>
<p>Nunc ac dignissim magna. Vestibulum vitae egestas elit. Proin feugiat leo quis ante condimentum, eu ornare mauris feugiat. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Mauris cursus laoreet ex, dignissim bibendum est posuere iaculis. Suspendisse et maximus elit. In fringilla gravida ornare. Aenean id lectus pulvinar, sagittis felis nec, rutrum risus. Nam vel neque eu arcu blandit fringilla et in quam. Aliquam luctus est sit amet vestibulum eleifend. Phasellus elementum sagittis molestie. Proin tempor lorem arcu, at condimentum purus volutpat eu. Fusce et pellentesque ligula. Pellentesque id tellus at erat luctus fringilla. Suspendisse potenti.</p>
<p>Etiam maximus accumsan gravida. Maecenas at nunc dignissim, euismod enim ac, bibendum ipsum. Maecenas vehicula velit in nisl aliquet ultricies. Nam eget massa interdum, maximus arcu vel, pretium erat. Maecenas sit amet tempor purus, vitae aliquet nunc. Vivamus cursus urna velit, eleifend dictum magna laoreet ut. Duis eu erat mollis, blandit magna id, tincidunt ipsum. Integer massa nibh, commodo eu ex vel, venenatis efficitur ligula. Integer convallis lacus elit, maximus eleifend lacus ornare ac. Vestibulum scelerisque viverra urna id lacinia. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia curae; Aenean eget enim at diam bibendum tincidunt eu non purus. Nullam id magna ultrices, sodales metus viverra, tempus turpis.</p>
<p>Duis ornare ex ac iaculis pretium. Maecenas sagittis odio id erat pharetra, sit amet consectetur quam sollicitudin. Vivamus pharetra quam purus, nec sagittis risus pretium at. Nullam feugiat, turpis ac accumsan interdum, sem tellus blandit neque, id vulputate diam quam semper nisl. Donec sit amet enim at neque porttitor aliquet. Phasellus facilisis nulla eget placerat eleifend. Vestibulum non egestas eros, eget lobortis ipsum. Nulla rutrum massa eget enim aliquam, id porttitor erat luctus. Nunc sagittis quis eros eu sagittis. Pellentesque dictum, erat at pellentesque sollicitudin, justo augue pulvinar metus, quis rutrum est mi nec felis. Vestibulum efficitur mi lorem, at elementum purus tincidunt a. Aliquam finibus enim magna, vitae pellentesque erat faucibus at. Nulla mauris tellus, imperdiet id lobortis et, dignissim condimentum ipsum. Morbi nulla orci, varius at aliquet sed, facilisis id tortor. Donec ut urna nisi.</p>
<p>Aenean placerat luctus tortor vitae molestie. Nulla at aliquet nulla. Sed efficitur tellus orci, sed fringilla lectus laoreet eget. Vivamus maximus quam sit amet arcu dignissim, sed accumsan massa ullamcorper. Sed iaculis tincidunt feugiat. Nulla in est at nunc ultricies dictum ut vitae nunc. Aenean convallis vel diam at malesuada. Suspendisse arcu libero, vehicula tempus ultrices a, placerat sit amet tortor. Sed dictum id nulla commodo mattis. Aliquam mollis, nunc eu tristique faucibus, purus lacus tincidunt nulla, ac pretium lorem nunc ut enim. Curabitur eget mattis nisl, vitae sodales augue. Nam felis massa, bibendum sit amet nulla vel, vulputate rutrum lacus. Aenean convallis odio pharetra nulla mattis consequat.</p>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div>CC SA BY-NC-ND</div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2024,
  author = {Bochman, Oren},
  title = {Chapter 3: {Linear} {Regression}},
  date = {2024-06-21},
  url = {https://orenbochman.github.io/notes-islr/posts/ch03-linear-regression/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2024" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2024. <span>“Chapter 3: Linear Regression.”</span> June
21, 2024. <a href="https://orenbochman.github.io/notes-islr/posts/ch03-linear-regression/">https://orenbochman.github.io/notes-islr/posts/ch03-linear-regression/</a>.
</div></div></section></div> ]]></description>
  <category>notes</category>
  <category>edx</category>
  <category>podcast</category>
  <guid>https://orenbochman.github.io/notes-islr/posts/ch03-linear-regression/</guid>
  <pubDate>Thu, 20 Jun 2024 21:00:00 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/notes-islr/images/nlp-brain-wordcloud.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Chapter 2: Statistical Learning</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/notes-islr/posts/ch02-statistical-learning/</link>
  <description><![CDATA[ 






<div class="no-row-height column-margin column-container"><div id="fig-v2.1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v2.1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/ox0cKk7h4o0?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v2.1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Introduction to Regression Models
</figcaption>
</figure>
</div><div id="fig-v2.2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v2.2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/uFwbrdvrAJs?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v2.2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Dimensionality and Structured Models
</figcaption>
</figure>
</div><div id="fig-v2.3" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v2.3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/pvcEQfcO3pk?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v2.3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Introduction to Regression Models
</figcaption>
</figure>
</div><div id="fig-v2.4" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v2.4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/BMJQ3LQ_QKU?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v2.4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Classification
</figcaption>
</figure>
</div><div id="fig-v2.5" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v2.5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/L03A81OgLlk?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v2.5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: Lab: Introduction to R
</figcaption>
</figure>
</div></div>



<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
TL;DR - Statistical Learning
</div>
</div>
<div class="callout-body-container callout-body">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="../../images/in_a_nutshell.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Statistical Learning in a nutshell"><img src="https://orenbochman.github.io/notes-islr/images/in_a_nutshell.jpg" class="img-fluid figure-img" alt="Statistical Learning in a nutshell"></a></p>
<figcaption>Statistical Learning in a nutshell</figcaption>
</figure>
</div>
<p>Statistical learning is a set of tools for understanding data and building models that can be used for prediction or inference. The fundamental goal is to learn a function <img src="https://latex.codecogs.com/png.latex?(f)"> that captures the relationship between input variables (predictors) and an output variable (response). This learned function can then be used to make predictions for new observations or for inference i.e.&nbsp;to understand the underlying relationship between the variables.</p>
<audio controls="1">
<source src="podcast.mp3" data-external="1" type="audio/mpeg">

</audio>
</div>
</div>
<p>The chapter is 53 pages long and covers the following topics:</p>
<ul>
<li>What Is Statistical Learning?</li>
<li>Why Estimate <img src="https://latex.codecogs.com/png.latex?f"> ?</li>
<li>How Do We Estimate <img src="https://latex.codecogs.com/png.latex?f"> ?</li>
<li>The Prediction Accuracy Trade-Off</li>
<li>Model Interpretability</li>
<li>Supervised Versus Unsupervised Learning</li>
<li>Regression Versus Classification Problems</li>
<li>Assessing Model Accuracy
<ul>
<li>Measuring the Quality of Fit</li>
<li>The Bias-Variance Trade-Off</li>
</ul></li>
<li>The Classification Setting</li>
<li><a href="../../posts/ch02-statistical-learning/Ch02-statlearn-lab.html">Lab: Introduction to Python</a></li>
</ul>
<section id="key-terms-in-statistical-learning-and-machine-learning" class="level2">
<h2 class="anchored" data-anchor-id="key-terms-in-statistical-learning-and-machine-learning">Key Terms in Statistical Learning and Machine Learning</h2>
<dl>
<dt>Statistical Learning</dt>
<dd>
A set of tools for understanding data and building models that can be used for prediction or inference.
</dd>
<dt>Input Variables</dt>
<dd>
Predictors or features, denoted by X, used to predict the output variable.
</dd>
<dt>Output Variable</dt>
<dd>
The response or dependent variable, denoted by Y, being predicted.
</dd>
<dt>Error Term</dt>
<dd>
Represents the random variation in the output variable not explained by the input variables. Denoted by ε.
</dd>
<dt>Prediction</dt>
<dd>
Using a statistical learning model to accurately predict the output variable for new observations based on their input values.
</dd>
<dt>Inference</dt>
<dd>
Understanding the relationship between input and output variables, identifying important predictors, and quantifying their effects.
</dd>
<dt>Parametric Methods</dt>
<dd>
Model-based approaches that assume a specific functional form for f and estimate its parameters using training data. Examples include linear regression and logistic regression.
</dd>
<dt>Non-parametric Methods</dt>
<dd>
Flexible approaches that do not pre-specify a functional form for f and estimate it directly from the data. Examples include K-nearest neighbors and splines.
</dd>
<dt>Overfitting</dt>
<dd>
Occurs when a model is too flexible and fits the training data too closely, leading to poor generalization to new data.
</dd>
<dt>Bias</dt>
<dd>
Error resulting from incorrect assumptions about the true functional form of f.
</dd>
<dt>Variance</dt>
<dd>
The amount by which the estimated function f̂ changes when trained on different training datasets.
</dd>
<dt>Bias-Variance Trade-off</dt>
<dd>
The balance between model bias and variance, where more flexible models have higher variance but lower bias, and vice versa.
</dd>
<dt>Cross-validation</dt>
<dd>
A technique for evaluating a model’s performance by splitting the data into multiple folds and using each fold for training and testing, providing a more robust estimate of test error.
</dd>
<dt>Bayes Classifier</dt>
<dd>
A theoretical classifier that assigns each observation to the class with the highest conditional probability given its predictor values, achieving the lowest possible test error rate (Bayes error rate).
</dd>
<dt>K-nearest Neighbors (KNN)</dt>
<dd>
A non-parametric classification method that finds the K nearest neighbors to a test observation in the training data and estimates the conditional probability for each class based on the proportion of neighbors belonging to that class.
</dd>
</dl>
</section>
<section id="chapter-summary" class="level2">
<h2 class="anchored" data-anchor-id="chapter-summary">Chapter summary</h2>
<ol type="1">
<li>What is Statistical Learning?</li>
</ol>
<p><strong>Statistical learning</strong> uses data to learn about relationships between input variables (predictors) and an output variable (response). This relationship can be expressed as:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AY%20=%20f(X)%20+%20%CE%B5%0A"></p>
<p>where:</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?Y"> is the response variable.</li>
<li><img src="https://latex.codecogs.com/png.latex?X"> represents the predictors <img src="https://latex.codecogs.com/png.latex?(X_1,%20X_2,...,%20X_p)">.</li>
<li><img src="https://latex.codecogs.com/png.latex?f(X)"> is the unknown function capturing the systematic relationship between X and Y.</li>
<li><img src="https://latex.codecogs.com/png.latex?%CE%B5"> is a random error term with a mean of zero, independent of <img src="https://latex.codecogs.com/png.latex?X">.</li>
</ul>
<p>Statistical learning aims to estimate the function <img src="https://latex.codecogs.com/png.latex?f(X)"> from observed data, enabling:</p>
<ul>
<li><strong>Prediction</strong>: Using the estimated function <img src="https://latex.codecogs.com/png.latex?(f%CC%82)"> to predict <img src="https://latex.codecogs.com/png.latex?Y"> for new values of <img src="https://latex.codecogs.com/png.latex?X">:</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%C5%B6%20=%20f%CC%82(X)%0A"></p>
<ul>
<li><p>The accuracy of prediction is influenced by reducible error (due to imperfections in estimating f) and irreducible error (due to the inherent randomness represented by <img src="https://latex.codecogs.com/png.latex?%CE%B5">).</p></li>
<li><p><strong>Inference</strong>: Understanding the relationship between predictors and response. This involves determining which predictors are most important, quantifying the strength of the relationship, and exploring the nature of the association.</p></li>
</ul>
<ol start="2" type="1">
<li>Estimating <img src="https://latex.codecogs.com/png.latex?f(X)"></li>
</ol>
<p>There are two main approaches to estimating the function <img src="https://latex.codecogs.com/png.latex?f(X)">:</p>
<ul>
<li><p><strong>Parametric Methods</strong>: Assume a specific functional form for <img src="https://latex.codecogs.com/png.latex?f(X)">, like a linear model: <img src="https://latex.codecogs.com/png.latex?%0Af(X)%20=%20%CE%B2_0%20+%20%CE%B2_1X_1%20+%20%CE%B2_2X_2%20+%20...%20+%20%CE%B2_pX_p%0A"></p></li>
<li><p>This simplifies the problem to estimating the model’s parameters (<img src="https://latex.codecogs.com/png.latex?%CE%B2">s). However, parametric methods may be inaccurate if the assumed form doesn’t match the true relationship.</p></li>
<li><p><strong>Non-Parametric Methods</strong>: Don’t assume a specific form for <img src="https://latex.codecogs.com/png.latex?f(X)">, allowing for more flexibility. They try to fit the data as closely as possible while maintaining smoothness. Examples include thin-plate splines. These methods require careful tuning to prevent overfitting, where the model fits the training data perfectly but performs poorly on new data.</p></li>
</ul>
<ol start="3" type="1">
<li><p>Assessing Model Accuracy The choice of a suitable statistical learning method and its flexibility depends on the bias-variance trade-off:</p>
<ul>
<li><p><strong>Bias</strong>: Measures how much the estimated function <img src="https://latex.codecogs.com/png.latex?(f%CC%82)"> deviates from the true function <img src="https://latex.codecogs.com/png.latex?(f)"> on average. Inflexible methods tend to have higher bias.</p></li>
<li><p><strong>Variance</strong>: Quantifies the sensitivity of <img src="https://latex.codecogs.com/png.latex?f%CC%82"> to changes in the training data. More flexible methods typically exhibit higher variance.</p></li>
<li><p>The goal is to find the balance between bias and variance that minimizes the expected test error.</p></li>
</ul></li>
<li><p>Supervised vs.&nbsp;Unsupervised Learning</p>
<ul>
<li><p><strong>Supervised Learning</strong>: Uses labeled data, where the response variable <img src="https://latex.codecogs.com/png.latex?(Y)"> is known for each observation. Examples include regression and classification problems.</p></li>
<li><p><strong>Unsupervised Learning</strong>: Deals with unlabeled data, where the response variable is unknown. Techniques like clustering aim to identify groups or patterns in the data.</p></li>
</ul></li>
<li><p>Classification</p></li>
</ol>
<p>Classification problems involve predicting a qualitative (categorical) response variable. One common metric to assess the performance of classifiers is the error rate, which measures the proportion of incorrect predictions.</p>
<ul>
<li><p><strong>Bayes Classifier</strong>: A theoretical classifier that assigns each observation to the most likely class based on its predictors. It achieves the lowest possible error rate (Bayes error rate). However, the Bayes classifier is typically unattainable in practice, as it requires knowing the true conditional distribution of Y given X.</p></li>
<li><p><strong>K-Nearest Neighbors</strong> (KNN): A non-parametric classification method that estimates the conditional probability for each class by considering the closest K training observations to a test point. KNN requires selecting an appropriate value for K, balancing flexibility and overfitting.</p></li>
</ul>
<ol start="6" type="1">
<li>Python for Statistical Learning</li>
</ol>
<p>The chapter introduces basic Python commands and data manipulation techniques using libraries like NumPy and Pandas. It covers:</p>
<ul>
<li>Importing libraries, defining arrays and matrices, computing basic statistics, and generating random data.</li>
<li>Creating various plots (scatter plots, contour plots, heatmaps) using Matplotlib.</li>
<li>Subsetting and indexing data frames, handling missing values, using for loops and lambdas for data manipulation.</li>
</ul>
<p>These tools provide a foundation for applying statistical learning methods in practice.</p>
</section>
<section id="statistical-learning---test-your-understanding" class="level2">
<h2 class="anchored" data-anchor-id="statistical-learning---test-your-understanding">Statistical Learning - Test Your Understanding!</h2>
<ol type="1">
<li>What is the fundamental goal of statistical learning?</li>
<li>Differentiate between the input and output variables in a statistical learning model.</li>
<li>What is the role of the error term in the general form of the statistical learning model?</li>
<li>Explain the difference between prediction and inference in the context of statistical learning.</li>
<li>Describe the two main steps involved in parametric methods for estimating f.</li>
<li>What is a key advantage and a key disadvantage of non-parametric methods compared to parametric methods?</li>
<li>How does the concept of overfitting relate to the choice of flexibility in a statistical learning method?</li>
<li>Explain the bias-variance trade-off and its impact on model selection.</li>
<li>What is the Bayes classifier and why is it considered a gold standard in classification problems?</li>
<li>How does the K-nearest neighbors (KNN) classifier work?</li>
</ol>
<section id="answer-key" class="level3">
<h3 class="anchored" data-anchor-id="answer-key">Answer Key</h3>
<ol type="1">
<li><p>The fundamental goal of statistical learning is to use a set of data to learn a function (f) that captures the relationship between input variables (predictors) and an output variable (response). This learned function can then be used for prediction or inference.</p></li>
<li><p>Input variables, also known as predictors or features, are the variables used to predict the output variable. They are denoted by X. The output variable, also known as the response, is the variable being predicted, denoted by Y.</p></li>
<li><p>The error term (ε) represents the random variation in the output variable that cannot be explained by the input variables. It accounts for the inherent uncertainty and noise in the data.</p></li>
<li><p>Prediction focuses on accurately predicting the output variable (Y) for new observations based on their input values (X), often treating the model as a black box. Inference aims to understand the relationship between the input variables and the output variable, focusing on identifying important predictors and their effects on the response.</p></li>
<li><p>First, parametric methods assume a specific functional form for f, such as linear. Second, they estimate the parameters of the assumed function using the training data. For example, in a linear model, the parameters are the coefficients.</p></li>
<li><p>Non-parametric methods are more flexible and can capture complex relationships in the data without pre-specifying a functional form for f.&nbsp;However, this flexibility can lead to overfitting, where the model fits the training data too closely and performs poorly on new data.</p></li>
<li><p>Overfitting occurs when a model is too flexible and captures noise in the training data instead of the underlying signal. This results in high training accuracy but poor generalization to new data. Choosing an appropriate level of flexibility helps avoid overfitting.</p></li>
<li><p>The bias-variance trade-off refers to the balance between model bias (error from wrong assumptions about f) and variance (sensitivity to fluctuations in the training data). More flexible models have higher variance but lower bias, while less flexible models have lower variance but higher bias. Finding the optimal balance minimizes test error.</p></li>
<li><p>The Bayes classifier assigns each observation to the class with the highest conditional probability given its predictor values. It achieves the lowest possible test error rate (Bayes error rate) but is unattainable in practice because the true conditional probability distribution is unknown.</p></li>
<li><p>The KNN classifier finds the K nearest neighbors to a test observation in the training data based on a distance metric. It then estimates the conditional probability for each class based on the proportion of neighbors belonging to that class and classifies the test observation to the class with the highest estimated probability.</p></li>
</ol>
</section>
</section>
<section id="essay-questions" class="level2">
<h2 class="anchored" data-anchor-id="essay-questions">Essay Questions</h2>
<ol type="1">
<li><p>Discuss the differences between supervised and unsupervised learning, providing real-world examples of each.</p>
<p><strong>Supervised learning</strong> is the problem setting in which we have labels on the data. The label are not so much can be a category, a number.<br>
Our model will be shooting an arrow at a know target so it is easier to evaluate the model. This type of problems are broken into regression, classification, survival analysis, and time series analysis, and when learning from exprerience it becomes reinforcement learning.</p>
<p>In unsupervised learning we don’t have labels. Although we don’t have a target, this data is much easier to collect as labeling the data requires a significant effort and is often error prone. Typical problems are clustering, dimensionality reduction, and association rule learning. However many problems in natural language processing are unsupervised.</p>
<p>Another point is that the distinction isn’t so clear today we have <strong>semi-supervised learning</strong> where we have a small amount of labeled data and a large amount of unlabeled data. For example, LLM are pretrained on unsupervised data and then fine-tuned on supervised data.</p></li>
<li><p>Explain the concepts of reducible and irreducible error in statistical learning. How do these errors relate to the concept of the Bayes error rate?</p></li>
<li><p>Compare and contrast parametric and non-parametric methods for estimating f.&nbsp;What are the advantages and disadvantages of each approach? Provide specific examples of methods from each category.</p></li>
<li><p>Describe the concept of cross-validation. Why is it important, and how can it be used to improve model selection and assessment?</p></li>
<li><p>Discuss the challenges and considerations in choosing an appropriate level of flexibility for a statistical learning method. How does the bias-variance trade-off guide this decision? Explain the consequences of choosing a model that is too flexible or not flexible enough.</p></li>
</ol>
</section>
<section id="slides-and-chapter" class="level2">
<h2 class="anchored" data-anchor-id="slides-and-chapter">Slides and Chapter</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slides.pdf" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Chapter Slides"><embed src="slides.pdf" class="col-page" style="width:5in;height:3.8in"></a></p>
<figcaption>Chapter Slides</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="ch02.pdf" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Chapter"><embed src="ch02.pdf" class="col-page" width="800" height="1000"></a></p>
<figcaption>Chapter</figcaption>
</figure>
</div>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div>CC SA BY-NC-ND</div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2024,
  author = {Bochman, Oren},
  title = {Chapter 2: {Statistical} {Learning}},
  date = {2024-06-10},
  url = {https://orenbochman.github.io/notes-islr/posts/ch02-statistical-learning/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2024" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2024. <span>“Chapter 2: Statistical Learning.”</span>
June 10, 2024. <a href="https://orenbochman.github.io/notes-islr/posts/ch02-statistical-learning/">https://orenbochman.github.io/notes-islr/posts/ch02-statistical-learning/</a>.
</div></div></section></div> ]]></description>
  <category>notes</category>
  <category>edx</category>
  <category>podcast</category>
  <guid>https://orenbochman.github.io/notes-islr/posts/ch02-statistical-learning/</guid>
  <pubDate>Sun, 09 Jun 2024 21:00:00 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/notes-islr/images/nlp-brain-wordcloud.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Chapter 1: Introduction</title>
  <dc:creator>Oren Bochman</dc:creator>
  <link>https://orenbochman.github.io/notes-islr/posts/ch01-intro/</link>
  <description><![CDATA[ 






<div class="no-row-height column-margin column-container"><div id="fig-v1.1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v1.1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/LvySJGj-88U?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v1.1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Opening Remarks
</figcaption>
</figure>
</div><div id="fig-v1.2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-v1.2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/B9s8rpdNxU0?list=PLoROMvodv4rOzrYsAxzQyHb8n_RWNuS1e" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-v1.2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Examples and Framework
</figcaption>
</figure>
</div></div>
<ol type="1">
<li><p>This chapter doen’t have a lab and is a bit dull.</p></li>
<li><p>The authors make significant effort to breathe life into it in the talks. But humor and jokes aside. Most of the examples and datasets from the book and make them sound mildly interesting, but my impression of the advertising data and a few others is that this is just data and that they never worked for an advertising company where most of the queations raised are quite diavervegent to the ones considered in the book.</p></li>
<li><p>IBM’s Watson beating the Jeopardy champions was exciting before the advent of LLMs. In reality IBM poured lots of resources into this demonstration of being able to beat some poor humans with a massive database of trivia. Later IBM had a very big headache trying to sell Watson to companies. IT took 10 years for LLM assistant to become both useful and in scale. If we consider the slide from the video we would notice that the project is realy using reinfocement learnin and not statistical learning or machine learning methods that are covered in the book.</p></li>
<li><p>A second story they mention is <strong>Nate Silver</strong>’s Five Thirty Eight site for prediction of the presidential and other elections. I find it amusing they mention this as Nate Silver is not a statistician. In reality most people use statistics as a tool to get their job done and are not full time statisticans. Nate Silver is a “rock star”. It’s worth mentioning though that predicing elections is isn’t hard mathematically - the challange is getting the details right and Nate Silver is good at that and thus deserves a lot of respect. There is very intersting work by Gelman and Tukey before on this topic. In fact John Tukey like Silver gained a lot of recognition, not from his amazing work on EDA, including the boxplot, the JAckknife the Fast Fourier Transform, designing spy plaens, naming the bit and software but for running election polls on NBC from 1960 to 1980. And a final point is that the best models as far as I know are using Bayesian methods which are not covered in this book to any great detail.</p></li>
<li><p><strong>Spam Detection</strong> - is a good example of Statistical Learning. Building a binary classifier using logistic regression is faitly easy to do and the maths is quite straight forward. The devil here is in the details. And spam is a moving target as spammers keep improving. It seems though that the real solution isn’t somuch a good filter but to make spamming unprofitable by making it easy to fine/sue spammers.</p></li>
<li><p>It covers the three of the datasets used in the book.</p>
<ol type="1">
<li>Wage data</li>
<li>Stock market data</li>
<li>Gene Expression Data</li>
</ol></li>
<li><p>ISL <span class="citation" data-cites="ISL">(James et al. 2013)</span> is an introduction text. <span class="citation" data-cites="ESL">(Hastie, Tibshirani, and Friedman 2009)</span> is the more comprehensive text.</p></li>
<li><p>Statistical learning is the author’s preferred term for machine learning and it is a bit different in that it considers the data orriginating from a data generating process (DGP) and the main goal is to uncover this process. In traditional ML the focus is on prediction.</p></li>
</ol>
<section id="premises" class="level2">
<h2 class="anchored" data-anchor-id="premises">Premises:</h2>
<ul>
<li>Statistical learning is not a series of black boxes - we need to understand the way the cogs of models come together.</li>
<li>While it is important to know what job is performed by each cog, it is not necessary to have the skills to construct the machine inside the box!</li>
<li>The readers are interested in applying the methods to real-world problems.</li>
</ul>
</section>
<section id="slides-and-chapter" class="level2">
<h2 class="anchored" data-anchor-id="slides-and-chapter">Slides and Chapter</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slides.pdf" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Chapter Slides"><embed src="slides.pdf" class="col-page" style="width:5in;height:3.8in"></a></p>
<figcaption>Chapter Slides</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="ch01.pdf" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Chapter"><embed src="ch01.pdf" class="col-page" width="800" height="1000"></a></p>
<figcaption>Chapter</figcaption>
</figure>
</div>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0">
<div id="ref-ESL" class="csl-entry">
Hastie, T., R. Tibshirani, and J. H. Friedman. 2009. <em>The Elements of Statistical Learning: Data Mining, Inference, and Prediction</em>. Springer Series in Statistics. Springer. <a href="https://books.google.co.il/books?id=eBSgoAEACAAJ">https://books.google.co.il/books?id=eBSgoAEACAAJ</a>.
</div>
<div id="ref-ISL" class="csl-entry">
James, G., D. Witten, T. Hastie, and R. Tibshirani. 2013. <em>An Introduction to Statistical Learning: With Applications in r</em>. Springer Texts in Statistics. Springer New York. <a href="https://books.google.co.il/books?id=qcI_AAAAQBAJ">https://books.google.co.il/books?id=qcI_AAAAQBAJ</a>.
</div>
</div></section><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div>CC SA BY-NC-ND</div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2024,
  author = {Bochman, Oren},
  title = {Chapter 1: {Introduction}},
  date = {2024-06-01},
  url = {https://orenbochman.github.io/notes-islr/posts/ch01-intro/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2024" class="csl-entry quarto-appendix-citeas">
Bochman, Oren. 2024. <span>“Chapter 1: Introduction.”</span> June 1,
2024. <a href="https://orenbochman.github.io/notes-islr/posts/ch01-intro/">https://orenbochman.github.io/notes-islr/posts/ch01-intro/</a>.
</div></div></section></div> ]]></description>
  <category>notes</category>
  <category>edx</category>
  <guid>https://orenbochman.github.io/notes-islr/posts/ch01-intro/</guid>
  <pubDate>Fri, 31 May 2024 21:00:00 GMT</pubDate>
  <media:content url="https://orenbochman.github.io/notes-islr/images/nlp-brain-wordcloud.jpg" medium="image" type="image/jpeg"/>
</item>
</channel>
</rss>
